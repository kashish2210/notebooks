{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2daff707-b413-4f1c-b3a8-d788451db4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `C:\\Users\\asus4\\Desktop\\julia_notebokk`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nothing[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    " Pkg.rm.(keys(Pkg.project().dependencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f2a0620b-b0ac-40e6-8738-172385a8e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      " to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "using Pkg\n",
    "Pkg.add(\"ResumableFunctions\")\n",
    "Pkg.add(\"StatsBase\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"FFTW\")\n",
    "Pkg.add(\"NaNMath\")\n",
    "Pkg.add(\"FITSIO\")\n",
    "Pkg.add(\"Intervals\")\n",
    "Pkg.add(\"ProgressBars\")\n",
    "Pkg.add(\"Plots\")\n",
    "import Pkg\n",
    "Pkg.add([\"Distributions\", \"Statistics\" ,\"StatsBase\" ,\"HDF5\" ])\n",
    "using Test\n",
    "using FFTW, Distributions, Statistics, StatsBase, HDF5\n",
    "using DataFrames\n",
    "using ResumableFunctions, StatsBase, Statistics, DataFrames\n",
    "using FFTW, NaNMath, FITSIO, Intervals\n",
    "using ProgressBars: tqdm as show_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e025d2f9-2cb7-44ce-866e-13be1c13f821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.add([\n",
    "    \"Statistics\",\n",
    "    \"Distributions\",\n",
    "    \"Test\",\n",
    "    \"ResumableFunctions\",\n",
    "    \"StatsBase\",  # Provides Histogram functionality\n",
    "    \"Tables\",\n",
    "    \"AbstractFFTs\"\n",
    "])\n",
    "using Statistics\n",
    "using Distributions\n",
    "using Test\n",
    "using ResumableFunctions\n",
    "using StatsBase\n",
    "using Tables\n",
    "using NaNMath\n",
    "using AbstractFFTs\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "48eaa33f-dc20-4f3b-8099-1f1c728dd69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_fourier  | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m1.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_fts_from_segments_cts_and_events_are_equal\", Any[], 1, false, false, true, 1.742275953879e9, 1.742275954778e9, false, \"In[140]\")], 2, false, false, true, 1.742275952941e9, 1.742275954778e9, false, \"In[140]\")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@resumable function get_flux_iterable_from_segments(\n",
    "    times::AbstractVector{<:Real}, \n",
    "    gti::AbstractMatrix{<:Real}, \n",
    "    segment_size::Real; \n",
    "    n_bin=nothing, fluxes=nothing, errors=nothing\n",
    ")\n",
    "    dt = nothing\n",
    "    binned = !isnothing(fluxes)\n",
    "    if binned\n",
    "        dt = Statistics.median(diff(@view times[1:min(100, end)]))\n",
    "    end\n",
    "    fun = _which_segment_idx_fun(; binned, dt)\n",
    "\n",
    "    for (s, e, idx0, idx1) in fun(times, gti, segment_size)\n",
    "        if idx1 - idx0 < 2\n",
    "            @yield nothing\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        if !binned\n",
    "            event_times = @view times[idx0:idx1-1]\n",
    "            cts = fit(Histogram, float.(event_times .- s), nbins=n_bin).weights\n",
    "        else\n",
    "            cts = float.(@view fluxes[idx0+1:idx1])\n",
    "            if !isnothing(errors)\n",
    "                cts = NamedTuple{(:counts, :errors)}((cts, @view errors[idx0+1:idx1]))\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        @yield cts\n",
    "    end\n",
    "end\n",
    "\n",
    "function compare_tables(table1::DataFrame, table2::DataFrame; rtol=0.001, discard=Vector{Symbol}())\n",
    "    s_discard = Set(Symbol.(discard))\n",
    "    test_result = true\n",
    "\n",
    "    # Ensure both DataFrames have the same columns before comparison\n",
    "    common_columns = intersect(propertynames(table1), propertynames(table2))\n",
    "    common_columns = setdiff(common_columns, s_discard)  # Remove discarded columns\n",
    "\n",
    "    for key in common_columns\n",
    "        oe, oc = getproperty(table1, key), getproperty(table2, key)\n",
    "        \n",
    "        if eltype(oe) <: Number && eltype(oc) <: Number\n",
    "            if !(≈(oe, oc, rtol=rtol))\n",
    "                test_result = false\n",
    "                @warn \"Mismatch in column $key: Maximum difference $(maximum(abs.(oe .- oc)))\"\n",
    "                break\n",
    "            end\n",
    "        else\n",
    "            if !(oe == oc)\n",
    "                test_result = false\n",
    "                @warn \"Mismatch in column $key: Values do not match\"\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @test test_result\n",
    "end\n",
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @test get_average_ctrate(times, gti, segment_size) == ctrate\n",
    "    @test get_average_ctrate(bin_times, gti, segment_size; counts=counts) == ctrate\n",
    "\n",
    "    @testset \"test_fts_from_segments_cts_and_events_are_equal\" begin\n",
    "        N = round(Int, segment_size / dt)\n",
    "        fts_evts = collect(get_flux_iterable_from_segments(times, gti, segment_size, n_bin=N))\n",
    "        fts_cts = collect(get_flux_iterable_from_segments(\n",
    "                bin_times, gti, segment_size, fluxes=counts))\n",
    "        @test fts_evts == fts_cts\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "86453558-7c3e-42b7-939c-737043391dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_fourier  | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m1.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_error_on_averaged_cross_spectrum_low_nave\", Any[], 2, false, false, true, 1.742275955135e9, 1.742275956462e9, false, \"In[141]\")], 2, false, false, true, 1.742275954819e9, 1.742275956462e9, false, \"In[141]\")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function error_on_averaged_cross_spectrum(\n",
    "    cross_power::AbstractVector{<:Complex}, \n",
    "    seg_power::AbstractVector{<:Real}, \n",
    "    ref_power::AbstractVector{<:Real}, n_ave::Integer,\n",
    "    seg_power_noise::Real, ref_power_noise::Real;\n",
    "    common_ref::Bool=false)\n",
    "\n",
    "    if n_ave < 30\n",
    "        @warn \"n_ave is below 30. Please note that the error bars \n",
    "        on the quantities derived from the cross spectrum \n",
    "        are only reliable for a large number of averaged \n",
    "        powers.\"\n",
    "    end\n",
    "    \n",
    "    two_n_ave = 2 * n_ave\n",
    "    if common_ref\n",
    "        Gsq = real.(cross_power .* conj(cross_power))\n",
    "        bsq = bias_term.(seg_power, ref_power, seg_power_noise, ref_power_noise, n_ave)\n",
    "        frac = @. (Gsq - bsq) / (ref_power - ref_power_noise)\n",
    "        power_over_2n = ref_power / two_n_ave\n",
    "\n",
    "        dRe = dIm = dG = @. NaNMath.sqrt(power_over_2n * (seg_power - frac))\n",
    "        dphi = @. NaNMath.sqrt(power_over_2n * (seg_power / (Gsq - bsq) -\n",
    "                       1 / (ref_power - ref_power_noise)))\n",
    "    else\n",
    "        PrPs = ref_power .* seg_power\n",
    "        dRe = @. NaNMath.sqrt((PrPs + real(cross_power) ^ 2 - imag(cross_power) ^ 2) / two_n_ave)\n",
    "        dIm = @. NaNMath.sqrt((PrPs - real(cross_power) ^ 2 + imag(cross_power) ^ 2) / two_n_ave)\n",
    "        gsq = raw_coherence.(cross_power, seg_power, ref_power, seg_power_noise, ref_power_noise, n_ave)\n",
    "        dphi = @. NaNMath.sqrt((1 - gsq) / (2 * gsq * n_ave))\n",
    "        dG = sqrt.(PrPs ./ n_ave)\n",
    "    end\n",
    "\n",
    "    return dRe, dIm, dphi, dG\n",
    "end\n",
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @test get_average_ctrate(times, gti, segment_size) == ctrate\n",
    "    @test get_average_ctrate(bin_times, gti, segment_size; counts=counts) == ctrate\n",
    "\n",
    "\n",
    "\n",
    "    @testset \"test_error_on_averaged_cross_spectrum_low_nave\" begin\n",
    "        for common_ref in [true, false]\n",
    "            @test_logs (:warn, r\"n_ave is below 30.\") error_on_averaged_cross_spectrum(\n",
    "                [4 + 1.0im], [2], [4], 29, 2, 2; common_ref=common_ref)\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d0cb5ee0-b042-458c-bce6-119289d4f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_fourier  | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_avg_pds_bad_input\", Any[], 1, false, false, true, 1.742275956803e9, 1.74227595684e9, false, \"In[142]\")], 2, false, false, true, 1.742275956496e9, 1.74227595684e9, false, \"In[142]\")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function avg_pds_from_events(\n",
    "    times::AbstractVector{<:Real}, gti::AbstractMatrix{<:Real},\n",
    "    segment_size::Real, dt::Real; norm::String=\"frac\",\n",
    "    use_common_mean::Bool=true, silent::Bool=false, \n",
    "    fluxes=nothing, errors=nothing)\n",
    "    \n",
    "    if isnothing(segment_size)\n",
    "        segment_size = maximum(gti) - minimum(gti)\n",
    "    end\n",
    "    n_bin = round(Int, segment_size / dt)\n",
    "    dt = segment_size / n_bin\n",
    "\n",
    "    flux_iterable = get_flux_iterable_from_segments(times, gti, segment_size;\n",
    "                                                    n_bin=n_bin, fluxes=fluxes,\n",
    "                                                    errors=errors)\n",
    "    result = avg_pds_from_iterable(flux_iterable, dt, norm=norm,\n",
    "                                  use_common_mean=use_common_mean,\n",
    "                                  silent=silent)\n",
    "    if isnothing(result)\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    return DataFrame(result)  # Ensure DataFrame output\n",
    "end\n",
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @test get_average_ctrate(times, gti, segment_size) == ctrate\n",
    "    @test get_average_ctrate(bin_times, gti, segment_size; counts=counts) == ctrate\n",
    "\n",
    "\n",
    "\n",
    "     @testset \"test_avg_pds_bad_input\" begin\n",
    "        _times = rand(Uniform(0,1000),1)\n",
    "        out_ev = avg_pds_from_events(_times, gti, segment_size, dt, silent=true)\n",
    "        @test isnothing(out_ev)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b782ad15-f9ce-413c-92df-60d4dcbcd2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_fourier  | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_avg_cs_bad_input\", Any[], 2, false, false, true, 1.742275957855e9, 1.742275957887e9, false, \"In[143]\")], 2, false, false, true, 1.742275957594e9, 1.742275957887e9, false, \"In[143]\")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function avg_cs_from_iterables(\n",
    "    flux_iterable1,\n",
    "    flux_iterable2,\n",
    "    dt::Real;\n",
    "    norm::String=\"frac\",\n",
    "    use_common_mean::Bool=true,\n",
    "    silent::Bool=false,\n",
    "    fullspec::Bool=false,\n",
    "    power_type::String=\"all\",\n",
    "    return_auxil::Bool=false)\n",
    "    \n",
    "    local_show_progress = show_progress\n",
    "    if silent\n",
    "        local_show_progress = (a) -> a\n",
    "    end\n",
    "    # Initialize stuff\n",
    "    cross = unnorm_cross = unnorm_pds1 = unnorm_pds2 = pds1 = pds2 = nothing\n",
    "    n_ave = 0\n",
    "    fgt0 = n_bin = freq = nothing\n",
    "\n",
    "    sum_of_photons1 = sum_of_photons2 = 0\n",
    "    common_variance1 = common_variance2 = common_variance = nothing\n",
    "\n",
    "    for (flux1, flux2) in local_show_progress(zip(flux_iterable1,\n",
    "                                                flux_iterable2))\n",
    "        if isnothing(flux1) || isnothing(flux2) || all(iszero, flux1.counts) || all(iszero, flux2.counts)\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        # Does the flux iterable return the uncertainty?\n",
    "        # If so, define the variances\n",
    "        variance1 = variance2 = nothing\n",
    "        if hasproperty(flux1, :errors)\n",
    "            err1 = flux1.errors\n",
    "            variance1 = Statistics.mean(err1) ^ 2\n",
    "        end\n",
    "        if hasproperty(flux2, :errors)\n",
    "            err2 = flux2.errors\n",
    "            variance2 = Statistics.mean(err2) ^ 2\n",
    "        end\n",
    "\n",
    "        # Only use the variance if both flux iterables define it.\n",
    "        if isnothing(variance1) || isnothing(variance2) \n",
    "            variance1 = variance2 = nothing\n",
    "        else\n",
    "            common_variance1 = sum_if_not_none_or_initialize(common_variance1,\n",
    "                                                             variance1)\n",
    "            common_variance2 = sum_if_not_none_or_initialize(common_variance2,\n",
    "                                                             variance2)\n",
    "        end\n",
    "\n",
    "        n_bin = length(flux1.counts)\n",
    "\n",
    "        # At the first loop, we define the frequency array and the range of\n",
    "        # positive frequency bins (after the first loop, cross will not be\n",
    "        # nothing anymore)\n",
    "        if isnothing(cross)\n",
    "            freq = fftfreq(n_bin, dt)\n",
    "            fgt0 = positive_fft_bins(n_bin)\n",
    "        end\n",
    "\n",
    "        # Calculate the FFTs\n",
    "        ft1 = fft(flux1.counts)\n",
    "        ft2 = fft(flux2.counts)\n",
    "\n",
    "        # Calculate the sum of each light curve, to calculate the mean\n",
    "        n_ph1 = sum(flux1.counts)\n",
    "        n_ph2 = sum(flux2.counts)\n",
    "        n_ph = sqrt(n_ph1 * n_ph2)\n",
    "\n",
    "        # Calculate the unnormalized cross spectrum\n",
    "        unnorm_power = ft1 .* conj.(ft2)\n",
    "\n",
    "        # If requested, calculate the auxiliary PDSs\n",
    "        if return_auxil\n",
    "            unnorm_pd1 = real.(ft1 .* conj.(ft1))\n",
    "            unnorm_pd2 = real.(ft2 .* conj.(ft2))\n",
    "        end\n",
    "\n",
    "        # Accumulate the sum to calculate the total mean of the lc\n",
    "        sum_of_photons1 += n_ph1\n",
    "        sum_of_photons2 += n_ph2\n",
    "\n",
    "        # Take only positive frequencies unless the user wants the full\n",
    "        # spectrum\n",
    "        if !(fullspec)\n",
    "            keepat!(unnorm_power, fgt0)\n",
    "            if return_auxil\n",
    "                keepat!(unnorm_pd1, fgt0)\n",
    "                keepat!(unnorm_pd2, fgt0)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        cs_seg = unnorm_power\n",
    "        if return_auxil\n",
    "            p1_seg = unnorm_pd1\n",
    "            p2_seg = unnorm_pd2\n",
    "        end\n",
    "\n",
    "        # If normalization has to be done interval by interval, do it here.\n",
    "        if !(use_common_mean)\n",
    "            mean1 = n_ph1 / n_bin\n",
    "            mean2 = n_ph2 / n_bin\n",
    "            mean = n_ph / n_bin\n",
    "            variance = nothing\n",
    "\n",
    "            if !isnothing(variance1)\n",
    "                variance = sqrt(variance1 * variance2)\n",
    "            end\n",
    "\n",
    "            cs_seg = normalize_periodograms(\n",
    "                unnorm_power, dt, n_bin; mean_flux = mean, n_ph=n_ph, norm=norm,\n",
    "                power_type=power_type, variance=variance\n",
    "            )\n",
    "\n",
    "            if return_auxil\n",
    "                p1_seg = normalize_periodograms(\n",
    "                    unnorm_pd1, dt, n_bin; mean_flux = mean1, n_ph=n_ph1, norm=norm,\n",
    "                    power_type=power_type, variance=variance1\n",
    "                )\n",
    "                p2_seg = normalize_periodograms(\n",
    "                    unnorm_pd2, dt, n_bin; mean_flux = mean2, n_ph=n_ph2, norm=norm,\n",
    "                    power_type=power_type, variance=variance2\n",
    "                )\n",
    "            end\n",
    "        end\n",
    "        # Initialize or accumulate final averaged spectra\n",
    "        cross = sum_if_not_none_or_initialize(cross, cs_seg)\n",
    "        unnorm_cross = sum_if_not_none_or_initialize(unnorm_cross,\n",
    "                                                     unnorm_power)\n",
    "\n",
    "        if return_auxil\n",
    "            unnorm_pds1 = sum_if_not_none_or_initialize(unnorm_pds1,\n",
    "                                                        unnorm_pd1)\n",
    "            unnorm_pds2 = sum_if_not_none_or_initialize(unnorm_pds2,\n",
    "                                                        unnorm_pd2)\n",
    "            pds1 = sum_if_not_none_or_initialize(pds1, p1_seg)\n",
    "            pds2 = sum_if_not_none_or_initialize(pds2, p2_seg)\n",
    "        end\n",
    "\n",
    "        n_ave += 1\n",
    "    end\n",
    "\n",
    "    # If no valid intervals were found, return only `nothing`s\n",
    "    if isnothing(cross)\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    # Calculate the mean number of photons per chunk\n",
    "    n_ph1 = sum_of_photons1 / n_ave\n",
    "    n_ph2 = sum_of_photons2 / n_ave\n",
    "    n_ph = sqrt(n_ph1 * n_ph2)\n",
    "\n",
    "    # Calculate the common mean number of photons per bin\n",
    "    common_mean1 = n_ph1 / n_bin\n",
    "    common_mean2 = n_ph2 / n_bin\n",
    "    common_mean = n_ph / n_bin\n",
    "\n",
    "    if !isnothing(common_variance1)\n",
    "        # Note: the variances we summed were means, not sums. Hence M, not M*N\n",
    "        common_variance1 /= n_ave\n",
    "        common_variance2 /= n_ave\n",
    "        common_variance = sqrt(common_variance1 * common_variance2)\n",
    "    end\n",
    "\n",
    "    # Transform the sums into averages\n",
    "    cross ./= n_ave\n",
    "    unnorm_cross ./= n_ave\n",
    "    if return_auxil\n",
    "        unnorm_pds1 ./= n_ave\n",
    "        unnorm_pds2 ./= n_ave\n",
    "    end\n",
    "\n",
    "    # Finally, normalize the cross spectrum (only if not already done on an\n",
    "    # interval-to-interval basis)\n",
    "    if use_common_mean\n",
    "        cross = normalize_periodograms(\n",
    "            unnorm_cross,\n",
    "            dt,\n",
    "            n_bin;\n",
    "            mean_flux = common_mean,\n",
    "            n_ph=n_ph,\n",
    "            norm=norm,\n",
    "            variance=common_variance,\n",
    "            power_type=power_type,\n",
    "        )\n",
    "        if return_auxil\n",
    "            pds1 = normalize_periodograms(\n",
    "                unnorm_pds1,\n",
    "                dt,\n",
    "                n_bin;\n",
    "                mean_flux = common_mean1,\n",
    "                n_ph=n_ph1,\n",
    "                norm=norm,\n",
    "                variance=common_variance1,\n",
    "                power_type=power_type,\n",
    "            )\n",
    "            pds2 = normalize_periodograms(\n",
    "                unnorm_pds2,\n",
    "                dt,\n",
    "                n_bin;\n",
    "                mean_flux = common_mean2,\n",
    "                n_ph=n_ph2,\n",
    "                norm=norm,\n",
    "                variance=common_variance2,\n",
    "                power_type=power_type,\n",
    "            )\n",
    "        end\n",
    "    end\n",
    "    # If the user does not want negative frequencies, don't give them\n",
    "    if !(fullspec)\n",
    "        freq = freq[fgt0]\n",
    "    end\n",
    "\n",
    "    # Create DataFrame with the computed data\n",
    "    results = DataFrame()\n",
    "    results[!,\"freq\"] = freq\n",
    "    results[!,\"power\"] = cross\n",
    "    results[!,\"unnorm_power\"] = unnorm_cross\n",
    "\n",
    "    if return_auxil\n",
    "        results[!,\"pds1\"] = pds1\n",
    "        results[!,\"pds2\"] = pds2\n",
    "        results[!,\"unnorm_pds1\"] = unnorm_pds1\n",
    "        results[!,\"unnorm_pds2\"] = unnorm_pds2\n",
    "    end\n",
    "\n",
    "    # Create NamedTuple with metadata instead of using attach_metadata\n",
    "    metadata = (\n",
    "        n = n_bin, \n",
    "        m = n_ave, \n",
    "        dt = dt,\n",
    "        norm = norm,\n",
    "        df = 1 / (dt * n_bin),\n",
    "        segment_size = dt * n_bin,\n",
    "        nphots = n_ph,\n",
    "        nphots1 = n_ph1, \n",
    "        nphots2 = n_ph2,\n",
    "        countrate1 = common_mean1 / dt,\n",
    "        countrate2 = common_mean2 / dt,\n",
    "        mean = common_mean,\n",
    "        mean1 = common_mean1,\n",
    "        mean2 = common_mean2,\n",
    "        power_type = power_type,\n",
    "        fullspec = fullspec,\n",
    "        variance = common_variance,\n",
    "        variance1 = common_variance1,\n",
    "        variance2 = common_variance2\n",
    "    )\n",
    "    \n",
    "    # Return both DataFrame and metadata as a tuple\n",
    "    return (results, metadata)\n",
    "end\n",
    "function avg_cs_from_iterables_quick(flux_iterable1, flux_iterable2,\n",
    "                                     dt::Real; norm::String=\"frac\")\n",
    "    unnorm_cross = unnorm_pds1 = unnorm_pds2 = nothing\n",
    "    n_ave = 0\n",
    "    fgt0 = n_bin = freq = nothing\n",
    "    sum_of_photons1 = sum_of_photons2 = 0\n",
    "    for (flux1, flux2) in zip(flux_iterable1, flux_iterable2)\n",
    "        if isnothing(flux1) || isnothing(flux2) || all(iszero, flux1.counts) || all(iszero, flux2.counts)\n",
    "            continue\n",
    "        end\n",
    "        n_bin = length(flux1.counts)\n",
    "        # Calculate the sum of each light curve, to calculate the mean\n",
    "        n_ph1 = sum(flux1.counts)\n",
    "        n_ph2 = sum(flux2.counts)\n",
    "        # At the first loop, we define the frequency array and the range of\n",
    "        # positive frequency bins (after the first loop, cross will not be\n",
    "        # nothing anymore)\n",
    "        if isnothing(unnorm_cross)\n",
    "            freq = fftfreq(n_bin, dt)\n",
    "            fgt0 = positive_fft_bins(n_bin)\n",
    "        end\n",
    "        # Calculate the FFTs\n",
    "        ft1 = fft(flux1.counts)\n",
    "        ft2 = fft(flux2.counts)\n",
    "        # Calculate the unnormalized cross spectrum\n",
    "        unnorm_power = ft1 .* conj.(ft2)\n",
    "        # Accumulate the sum to calculate the total mean of the lc\n",
    "        sum_of_photons1 += n_ph1\n",
    "        sum_of_photons2 += n_ph2\n",
    "        # Take only positive frequencies\n",
    "        keepat!(unnorm_power, fgt0)\n",
    "        # Initialize or accumulate final averaged spectrum\n",
    "        unnorm_cross = sum_if_not_none_or_initialize(unnorm_cross,\n",
    "                                                     unnorm_power)\n",
    "        n_ave += 1\n",
    "    end\n",
    "    # If no valid intervals were found, return only `nothing`s\n",
    "    if isnothing(unnorm_cross)\n",
    "        return nothing\n",
    "    end\n",
    "    # Calculate the mean number of photons per chunk\n",
    "    n_ph1 = sum_of_photons1 / n_ave\n",
    "    n_ph2 = sum_of_photons2 / n_ave\n",
    "    n_ph = sqrt(n_ph1 * n_ph2)\n",
    "    # Calculate the mean number of photons per bin\n",
    "    common_mean1 = n_ph1 / n_bin\n",
    "    common_mean2 = n_ph2 / n_bin\n",
    "    common_mean = n_ph / n_bin\n",
    "    # Transform the sums into averages\n",
    "    unnorm_cross ./= n_ave\n",
    "    # Finally, normalize the cross spectrum (only if not already done on an\n",
    "    # interval-to-interval basis)\n",
    "    cross = normalize_periodograms(\n",
    "        unnorm_cross,\n",
    "        dt,\n",
    "        n_bin;\n",
    "        mean_flux = common_mean,\n",
    "        n_ph=n_ph,\n",
    "        norm=norm,\n",
    "        variance=nothing,\n",
    "        power_type=\"all\",\n",
    "    )\n",
    "    # No negative frequencies\n",
    "    freq = freq[fgt0]\n",
    "    \n",
    "    # Create DataFrame with the computed data\n",
    "    results = DataFrame()\n",
    "    results[!,\"freq\"] = freq\n",
    "    results[!,\"power\"] = cross\n",
    "    results[!,\"unnorm_power\"] = unnorm_cross\n",
    "    \n",
    "    # Create NamedTuple with metadata instead of using attach_metadata\n",
    "    metadata = (\n",
    "        n = n_bin, \n",
    "        m = n_ave, \n",
    "        dt = dt,\n",
    "        norm = norm,\n",
    "        df = 1 / (dt * n_bin),\n",
    "        nphots = n_ph,\n",
    "        nphots1 = n_ph1, \n",
    "        nphots2 = n_ph2,\n",
    "        variance = nothing,\n",
    "        mean = common_mean,\n",
    "        mean1 = common_mean1,\n",
    "        mean2 = common_mean2,\n",
    "        power_type = \"all\",\n",
    "        fullspec = false,\n",
    "        segment_size = dt * n_bin\n",
    "    )\n",
    "    \n",
    "    # Return both DataFrame and metadata as a tuple\n",
    "    return (results, metadata)\n",
    "end\n",
    "function avg_cs_from_events(\n",
    "    times1:: AbstractVector{<:Real}, times2:: AbstractVector{<:Real},\n",
    "    gti::AbstractMatrix{<:Real}, segment_size::Real, dt::Real;\n",
    "    norm::String=\"frac\", use_common_mean::Bool=true,\n",
    "    fullspec::Bool=false, silent::Bool=false,\n",
    "    power_type::String=\"all\", fluxes1=nothing, fluxes2=nothing,\n",
    "    errors1=nothing, errors2=nothing, return_auxil=false)\n",
    "    \n",
    "    if isnothing(segment_size) \n",
    "        segment_size = max(gti) - min(gti)\n",
    "    end\n",
    "    n_bin = round(Int, segment_size / dt)\n",
    "    dt = segment_size / n_bin\n",
    "\n",
    "    flux_iterable1 = get_flux_iterable_from_segments(\n",
    "        times1, gti, segment_size; n_bin=n_bin, fluxes=fluxes1, errors=errors1\n",
    "    )\n",
    "    flux_iterable2 = get_flux_iterable_from_segments(\n",
    "        times2, gti, segment_size; n_bin=n_bin, fluxes=fluxes2, errors=errors2\n",
    "    )\n",
    "\n",
    "    is_events = all(isnothing, (fluxes1, fluxes2, errors1, errors2))\n",
    "\n",
    "    if (is_events && silent && use_common_mean && power_type == \"all\" && !fullspec && !return_auxil)\n",
    "        results = avg_cs_from_iterables_quick(\n",
    "            flux_iterable1,\n",
    "            flux_iterable2,\n",
    "            dt;\n",
    "            norm=norm\n",
    "        )\n",
    "    else\n",
    "        results = avg_cs_from_iterables(\n",
    "            flux_iterable1,\n",
    "            flux_iterable2,\n",
    "            dt;\n",
    "            norm=norm,\n",
    "            use_common_mean=use_common_mean,\n",
    "            silent=silent,\n",
    "            fullspec=fullspec,\n",
    "            power_type=power_type,\n",
    "            return_auxil=return_auxil\n",
    "        )\n",
    "    end\n",
    "    if isnothing(results)\n",
    "        return nothing\n",
    "    end\n",
    "    return results[1]  # Return only the DataFrame, ignore metadata\n",
    "end\n",
    "\n",
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @test get_average_ctrate(times, gti, segment_size) == ctrate\n",
    "    @test get_average_ctrate(bin_times, gti, segment_size; counts=counts) == ctrate\n",
    "\n",
    "\n",
    "\n",
    "      @testset \"test_avg_cs_bad_input\" begin\n",
    "        for return_auxil in [true, false]\n",
    "            _times1 = rand(Uniform(0,1000),1)\n",
    "            _times2 = rand(Uniform(0,1000),1)\n",
    "            out_ev = avg_cs_from_events(_times1, _times2, gti,\n",
    "                                        segment_size, dt, silent=true, return_auxil=return_auxil)\n",
    "            @test isnothing(out_ev) \n",
    "        end\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4ff4c0e2-bf5b-49be-9317-90dd8098c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_fourier  | \u001b[32m  10  \u001b[39m\u001b[36m   10  \u001b[39m\u001b[0m0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_avg_pds_use_common_mean_similar_stats\", Any[], 8, false, false, true, 1.742275960113e9, 1.742275960519e9, false, \"In[144]\")], 2, false, false, true, 1.742275959757e9, 1.742275960519e9, false, \"In[144]\")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sum_if_not_none_or_initialize(current, new_value)\n",
    "    if isnothing(current)\n",
    "        if isa(new_value, AbstractArray)\n",
    "            return copy(new_value)\n",
    "        else\n",
    "            return new_value\n",
    "        end\n",
    "    else\n",
    "        if isa(current, AbstractArray) && isa(new_value, AbstractArray)\n",
    "            return current .+ new_value\n",
    "        else\n",
    "            return current + new_value\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "@resumable function get_flux_iterable_from_segments(\n",
    "    times::AbstractVector{<:Real}, \n",
    "    gti::AbstractMatrix{<:Real}, \n",
    "    segment_size::Real; \n",
    "    n_bin=nothing, fluxes=nothing, errors=nothing\n",
    ")\n",
    "    dt = nothing\n",
    "    binned = !isnothing(fluxes)\n",
    "    if binned\n",
    "        dt = Statistics.median(diff(@view times[1:min(100, end)]))\n",
    "    end\n",
    "    fun = _which_segment_idx_fun(; binned, dt)\n",
    "\n",
    "    for (s, e, idx0, idx1) in fun(times, gti, segment_size)\n",
    "        if idx1 - idx0 < 2\n",
    "            @yield nothing\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        if !binned\n",
    "            event_times = @view times[idx0:idx1-1]\n",
    "            cts = fit(Histogram, float.(event_times .- s), range(0, segment_size, length=n_bin+1)).weights\n",
    "            @yield NamedTuple{(:counts,)}((cts,))\n",
    "        else\n",
    "            counts = float.(@view fluxes[idx0+1:idx1])\n",
    "            if !isnothing(errors)\n",
    "                errors_slice = float.(@view errors[idx0+1:idx1])\n",
    "                if length(counts) == length(errors_slice)\n",
    "                    @yield NamedTuple{(:counts, :errors)}((counts, errors_slice))\n",
    "                else\n",
    "                    @yield nothing\n",
    "                end\n",
    "            else\n",
    "                @yield NamedTuple{(:counts,)}((counts,))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function avg_pds_from_iterable(flux_iterable, dt::Real; norm::String=\"frac\", \n",
    "                               use_common_mean::Bool=true,\n",
    "                               silent::Bool=false)\n",
    "    local_show_progress = identity\n",
    "    if silent\n",
    "        local_show_progress = identity\n",
    "    end\n",
    "\n",
    "    cross = unnorm_cross = nothing\n",
    "    n_ave = 0\n",
    "    freq = nothing\n",
    "\n",
    "    sum_of_photons = 0\n",
    "    common_variance = nothing\n",
    "    fgt0 = nothing\n",
    "    n_bin = nothing\n",
    "\n",
    "    for flux_tuple in local_show_progress(flux_iterable)\n",
    "        if isnothing(flux_tuple) || all(iszero, flux_tuple.counts)\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        flux = flux_tuple.counts\n",
    "        variance = nothing\n",
    "        if hasproperty(flux_tuple, :errors)\n",
    "            err = flux_tuple.errors\n",
    "            variance = Statistics.mean(err) ^ 2\n",
    "        end\n",
    "\n",
    "        n_bin = length(flux)\n",
    "        ft = fft(flux)\n",
    "        n_ph = sum(flux)\n",
    "        unnorm_power = real.(ft .* conj.(ft))\n",
    "\n",
    "        sum_of_photons += n_ph\n",
    "        if !isnothing(variance)\n",
    "            common_variance = sum_if_not_none_or_initialize(common_variance, variance)\n",
    "        end\n",
    "\n",
    "        if isnothing(cross)\n",
    "            fgt0 = positive_fft_bins(n_bin)\n",
    "            freq = fftfreq(n_bin, dt)[fgt0]\n",
    "        end\n",
    "\n",
    "        unnorm_power_filtered = unnorm_power[fgt0]\n",
    "        \n",
    "        cs_seg = unnorm_power_filtered\n",
    "        if !(use_common_mean)\n",
    "            mean = n_ph / n_bin\n",
    "            cs_seg = normalize_periodograms(\n",
    "                unnorm_power_filtered, dt, n_bin; mean_flux=mean, n_ph=n_ph,\n",
    "                norm=norm, variance=variance,\n",
    "            )\n",
    "        end\n",
    "\n",
    "        if isnothing(cross)\n",
    "            cross = copy(cs_seg)\n",
    "        else\n",
    "            cross .+= cs_seg\n",
    "        end\n",
    "        \n",
    "        if isnothing(unnorm_cross)\n",
    "            unnorm_cross = copy(unnorm_power_filtered)\n",
    "        else\n",
    "            unnorm_cross .+= unnorm_power_filtered\n",
    "        end\n",
    "        \n",
    "        n_ave += 1\n",
    "    end\n",
    "\n",
    "    if isnothing(cross)\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    n_ph = sum_of_photons / n_ave\n",
    "    common_mean = n_ph / n_bin\n",
    "\n",
    "    if !isnothing(common_variance)\n",
    "        common_variance /= n_ave\n",
    "    end\n",
    "\n",
    "    unnorm_cross ./= n_ave\n",
    "    cross ./= n_ave\n",
    "\n",
    "    if use_common_mean\n",
    "        cross = normalize_periodograms(\n",
    "            unnorm_cross, dt, n_bin; mean_flux=common_mean, n_ph=n_ph,\n",
    "            norm=norm, variance=common_variance\n",
    "        )\n",
    "    end\n",
    "\n",
    "    results = DataFrame()\n",
    "    results.freq = freq\n",
    "    results.power = cross\n",
    "    results.unnorm_power = unnorm_cross\n",
    "\n",
    "    return results\n",
    "end\n",
    "\n",
    "function avg_pds_from_events(\n",
    "    times::AbstractVector{<:Real}, gti::AbstractMatrix{<:Real},\n",
    "    segment_size::Real, dt::Real; norm::String=\"frac\",\n",
    "    use_common_mean::Bool=true, silent::Bool=false, \n",
    "    fluxes=nothing, errors=nothing)\n",
    "    \n",
    "    if isnothing(segment_size)\n",
    "        segment_size = maximum(gti) - minimum(gti)\n",
    "    end\n",
    "    n_bin = round(Int, segment_size / dt)\n",
    "    dt = segment_size / n_bin\n",
    "\n",
    "    flux_iterable = get_flux_iterable_from_segments(times, gti, segment_size;\n",
    "                                                    n_bin=n_bin, fluxes=fluxes,\n",
    "                                                    errors=errors)\n",
    "    result = avg_pds_from_iterable(flux_iterable, dt, norm=norm,\n",
    "                                  use_common_mean=use_common_mean,\n",
    "                                  silent=silent)\n",
    "    if isnothing(result)\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    return DataFrame(result)  # Ensure DataFrame output\n",
    "end\n",
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @test get_average_ctrate(times, gti, segment_size) == ctrate\n",
    "    @test get_average_ctrate(bin_times, gti, segment_size; counts=counts) == ctrate\n",
    "    @testset \"test_avg_pds_use_common_mean_similar_stats\" begin\n",
    "        for norm in [\"frac\", \"abs\", \"none\", \"leahy\"]\n",
    "            out_comm = avg_pds_from_events(\n",
    "                times,\n",
    "                gti,\n",
    "                segment_size,\n",
    "                dt,\n",
    "                norm=norm,\n",
    "                use_common_mean=true,\n",
    "                silent=true,\n",
    "                fluxes=nothing,\n",
    "            )\n",
    "            \n",
    "            out = avg_pds_from_events(\n",
    "                times,\n",
    "                gti,\n",
    "                segment_size,\n",
    "                dt,\n",
    "                norm=norm,\n",
    "                use_common_mean=false,\n",
    "                silent=true,\n",
    "                fluxes=nothing,\n",
    "            )\n",
    "            \n",
    "            @test !isnothing(out_comm) && !isnothing(out)\n",
    "            @test std(out_comm.power) ≈ std(out.power) rtol=0.1\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "74fd85b5-78fc-4d6e-90a8-c1b23e9eb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1m Time\u001b[22m\n",
      "test_fourier  | \u001b[32m  48  \u001b[39m\u001b[36m   48  \u001b[39m\u001b[0m10.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_fourier\", Any[Test.DefaultTestSet(\"test_avg_cs_use_common_mean_similar_stats\", Any[], 16, false, false, true, 1.742275960885e9, 1.742275965611e9, false, \"In[145]\"), Test.DefaultTestSet(\"test_avg_pds_cts_and_events_are_equal\", Any[], 8, false, false, true, 1.742275965611e9, 1.742275967078e9, false, \"In[145]\"), Test.DefaultTestSet(\"test_avg_pds_cts_and_err_and_events_are_equal\", Any[], 8, false, false, true, 1.742275967078e9, 1.742275968733e9, false, \"In[145]\"), Test.DefaultTestSet(\"test_avg_cs_cts_and_events_are_equal\", Any[], 8, false, false, true, 1.742275968733e9, 1.742275969882e9, false, \"In[145]\"), Test.DefaultTestSet(\"test_avg_cs_cts_and_err_and_events_are_equal\", Any[], 8, false, false, true, 1.742275969882e9, 1.742275971323e9, false, \"In[145]\")], 0, false, false, true, 1.742275960582e9, 1.742275971323e9, false, \"In[145]\")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@testset \"test_fourier\" begin\n",
    "    dt = 1\n",
    "    len = 100\n",
    "    ctrate = 10000\n",
    "    N = len ÷ dt\n",
    "    dt = len / N\n",
    "    times = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    gti = [[0 len];;]\n",
    "    bins = LinRange(0, len, N + 1)\n",
    "    counts = fit(Histogram, times, bins).weights\n",
    "    errs = fill!(similar(counts), 1) * sqrt(ctrate)\n",
    "    bin_times = (@view(bins[1:end-1]) + @view(bins[2:end])) / 2\n",
    "    segment_size = 20.0\n",
    "    times2 = sort(rand(Uniform(0, len), len * ctrate))\n",
    "    counts2 = fit(Histogram, times2, bins).weights\n",
    "    errs2 = fill!(similar(counts2), 1) * sqrt(ctrate)\n",
    "\n",
    "    @testset \"test_avg_cs_use_common_mean_similar_stats\" begin\n",
    "        for norm in [\"frac\", \"abs\", \"none\", \"leahy\"], return_auxil in [true, false], fullspec in [true, false]\n",
    "            out_comm = avg_cs_from_events(times, times2, gti, segment_size, dt, norm=norm, use_common_mean=true, silent=true, fullspec=fullspec, return_auxil=return_auxil)[!, :power]\n",
    "            out = avg_cs_from_events(times, times2, gti, segment_size, dt, norm=norm, use_common_mean=false, silent=true, fullspec=fullspec, return_auxil=return_auxil)[!, :power]\n",
    "            @test std(out_comm) ≈ std(out) rtol=0.1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @testset \"test_avg_pds_cts_and_events_are_equal\" begin\n",
    "        for use_common_mean in [true, false], norm in [\"frac\", \"abs\", \"none\", \"leahy\"]\n",
    "            out_ev = avg_pds_from_events(times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes=nothing)\n",
    "            out_ct = avg_pds_from_events(bin_times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes=counts)\n",
    "            compare_tables(out_ev, out_ct)\n",
    "        end\n",
    "    end\n",
    "    @testset \"test_avg_pds_cts_and_err_and_events_are_equal\" begin\n",
    "        for use_common_mean in [true, false], norm in [\"frac\", \"abs\", \"none\", \"leahy\"]\n",
    "            out_ev = avg_pds_from_events(times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes=nothing)\n",
    "            out_ct = avg_pds_from_events(bin_times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes=counts, errors=errs)\n",
    "            if use_common_mean\n",
    "                compare_tables(out_ev, out_ct, rtol=0.01, discard=[\"variance\"])\n",
    "            else\n",
    "                compare_tables(out_ev, out_ct, rtol=0.1, discard=[\"variance\"])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @testset \"test_avg_cs_cts_and_events_are_equal\" begin\n",
    "        for use_common_mean in [true, false], norm in [\"frac\", \"abs\", \"none\", \"leahy\"]\n",
    "            out_ev = avg_cs_from_events(times, times2, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true)\n",
    "            out_ct = avg_cs_from_events(bin_times, bin_times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes1=counts, fluxes2=counts2)\n",
    "            if use_common_mean\n",
    "                compare_tables(out_ev, out_ct, rtol=0.01)\n",
    "            else\n",
    "                compare_tables(out_ev, out_ct, rtol=0.1)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @testset \"test_avg_cs_cts_and_err_and_events_are_equal\" begin\n",
    "        for use_common_mean in [true, false], norm in [\"frac\", \"abs\", \"none\", \"leahy\"]\n",
    "            out_ev = avg_cs_from_events(times, times2, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true)\n",
    "            out_ct = avg_cs_from_events(bin_times, bin_times, gti, segment_size, dt, norm=norm, use_common_mean=use_common_mean, silent=true, fluxes1=counts, fluxes2=counts2, errors1=errs, errors2=errs2)\n",
    "            discard = [m for m in propertynames(out_ev) if m == :variance]\n",
    "            if use_common_mean\n",
    "                compare_tables(out_ev, out_ct, rtol=0.01, discard=discard)\n",
    "            else\n",
    "                compare_tables(out_ev, out_ct, rtol=0.1, discard=discard)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "551f0968-ff1f-4efc-ae8f-d7ff5306b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "test_norm     | \u001b[32m  21  \u001b[39m\u001b[36m   21  \u001b[39m\u001b[0m1.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"test_norm\", Any[Test.DefaultTestSet(\"test_leahy_bksub_var_vs_standard\", Any[], 1, false, false, true, 1.742277957556e9, 1.742277958172e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_abs_bksub\", Any[], 1, false, false, true, 1.742277958172e9, 1.742277958184e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_frac_renorm_constant\", Any[], 1, false, false, true, 1.742277958184e9, 1.742277958193e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_frac_to_abs_ctratesq\", Any[], 1, false, false, true, 1.742277958193e9, 1.742277958765e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_total_variance\", Any[], 1, false, false, true, 1.742277958765e9, 1.742277958771e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_abs\", Any[], 1, false, false, true, 1.742277958771e9, 1.742277958775e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_frac\", Any[], 1, false, false, true, 1.742277958775e9, 1.742277958778e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_leahy\", Any[], 1, false, false, true, 1.742277958778e9, 1.742277958781e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_none\", Any[], 1, false, false, true, 1.742277958781e9, 1.742277958782e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_real_abs\", Any[], 1, false, false, true, 1.742277958782e9, 1.742277958792e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_real_frac\", Any[], 1, false, false, true, 1.742277958792e9, 1.742277958794e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_real_leahy\", Any[], 1, false, false, true, 1.742277958794e9, 1.742277958797e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_real_none\", Any[], 1, false, false, true, 1.742277958797e9, 1.742277958798e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_absolute_abs\", Any[], 1, false, false, true, 1.742277958798e9, 1.742277958804e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_absolute_frac\", Any[], 1, false, false, true, 1.742277958804e9, 1.742277958808e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_absolute_leahy\", Any[], 1, false, false, true, 1.742277958808e9, 1.742277958819e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_poisson_level_absolute_none\", Any[], 1, false, false, true, 1.742277958819e9, 1.742277958821e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_normalize_with_variance\", Any[], 1, false, false, true, 1.742277958821e9, 1.742277958823e9, false, \"In[151]\"), Test.DefaultTestSet(\"test_normalize_none\", Any[], 1, false, false, true, 1.742277958823e9, 1.742277958825e9, false, \"In[151]\")], 2, false, false, true, 1.742277956978e9, 1.742277958825e9, false, \"In[151]\")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_frac(unnorm_power::AbstractVector{<:Number}, dt::Real, n_bin::Integer, \n",
    "                        mean_flux::Real; background_flux::Real=0.0)\n",
    "    if background_flux > 0\n",
    "        power = @. unnorm_power * 2 * dt / ((mean_flux - background_flux) ^ 2 *\n",
    "                                          n_bin)\n",
    "    else\n",
    "        power = @. unnorm_power * 2 * dt / (mean_flux ^ 2 * n_bin)\n",
    "    end\n",
    "    return power\n",
    "end\n",
    "\n",
    "normalize_abs(unnorm_power::AbstractVector{<:Number}, dt::Real, n_bin::Integer) = \n",
    "    @. unnorm_power * 2 / n_bin / dt\n",
    "\n",
    "normalize_leahy_from_variance(unnorm_power::AbstractVector{<:Number}, \n",
    "                              variance::Real, n_bin::Integer) = \n",
    "    @. unnorm_power * 2 / (variance * n_bin)\n",
    "\n",
    "normalize_leahy_poisson(unnorm_power::AbstractVector{<:Number}, n_ph::Real) = \n",
    "    @. unnorm_power * 2 / n_ph\n",
    "\n",
    "function normalize_periodograms(unnorm_power::AbstractVector{<:Number}, dt::Real, \n",
    "                                n_bin::Integer; mean_flux=nothing, n_ph=nothing,\n",
    "                                variance=nothing, background_flux::Real=0.0, \n",
    "                                norm::String=\"frac\",power_type::String=\"all\")\n",
    "    \n",
    "    if norm == \"leahy\" && !isnothing(variance)\n",
    "        pds = normalize_leahy_from_variance(unnorm_power, variance, n_bin)\n",
    "    elseif norm == \"leahy\"\n",
    "        pds = normalize_leahy_poisson(unnorm_power, n_ph)\n",
    "    elseif norm == \"frac\"\n",
    "        pds = normalize_frac(\n",
    "            unnorm_power, dt, n_bin, mean_flux,\n",
    "            background_flux=background_flux)\n",
    "    elseif norm == \"abs\"\n",
    "        pds = normalize_abs(unnorm_power, dt, n_bin)\n",
    "    elseif norm == \"none\"\n",
    "        pds = unnorm_power\n",
    "    else \n",
    "        throw(ArgumentError(\"Unknown value for norm: $norm\"))\n",
    "    end\n",
    "\n",
    "    if power_type == \"all\"\n",
    "        return pds\n",
    "    elseif power_type == \"real\"\n",
    "        return real(pds)\n",
    "    elseif power_type in [\"abs\", \"absolute\"]\n",
    "        return abs.(pds)\n",
    "    else \n",
    "        throw(ArgumentError(\"Unknown value for power_type: $power_type\"))\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "@testset \"test_norm\" begin\n",
    "    mean = var = 100000\n",
    "    N = 1000000\n",
    "    dt = 0.2\n",
    "    meanrate = mean / dt\n",
    "    lc = rand(Poisson(mean), N)\n",
    "    pds = abs2.(fft(lc))\n",
    "    freq = fftfreq(N, dt)\n",
    "    good = 2:(N ÷ 2)\n",
    "\n",
    "    pdsabs = normalize_abs(pds, dt, size(lc, 1))\n",
    "    pdsfrac = normalize_frac(pds, dt, size(lc, 1), mean)\n",
    "    pois_abs = poisson_level(\"abs\", meanrate=meanrate)\n",
    "    pois_frac = poisson_level(\"frac\", meanrate=meanrate)\n",
    "\n",
    "    @test Statistics.mean(view(pdsabs, good)) ≈ pois_abs rtol=0.02\n",
    "    @test Statistics.mean(view(pdsfrac, good)) ≈ pois_frac rtol=0.02\n",
    "\n",
    "    mean = var = 100000.0\n",
    "    N = 800000\n",
    "    dt = 0.2\n",
    "    df = 1 / (N * dt)\n",
    "    freq = fftfreq(N, dt)\n",
    "    good = freq .> 0\n",
    "    meanrate = mean / dt\n",
    "    lc = rand(Poisson(mean), N)\n",
    "    nph = sum(lc)\n",
    "    pds = view(abs2.(fft(lc)), good)\n",
    "    lc_bksub = lc .- mean\n",
    "    pds_bksub = view(abs2.(fft(lc_bksub)), good)\n",
    "    lc_renorm = lc / mean\n",
    "    pds_renorm = view(abs2.(fft(lc_renorm)), good)\n",
    "    lc_renorm_bksub = lc_renorm .- 1\n",
    "    pds_renorm_bksub = view(abs2.(fft(lc_renorm_bksub)), good)\n",
    "\n",
    "    @testset \"test_leahy_bksub_var_vs_standard\" begin\n",
    "        leahyvar = normalize_leahy_from_variance(pds_bksub, Statistics.var(lc_bksub), N)\n",
    "        leahy = 2 .* pds ./ sum(lc)\n",
    "        ratio = Statistics.mean(leahyvar ./ leahy)\n",
    "        @test ratio ≈ 1 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_abs_bksub\" begin\n",
    "        ratio = normalize_abs(pds_bksub, dt, N) ./ normalize_abs(pds, dt, N)\n",
    "        @test Statistics.mean(ratio) ≈ 1 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_frac_renorm_constant\" begin\n",
    "        ratio = normalize_frac(pds_renorm, dt, N, 1) ./ normalize_frac(pds, dt, N, mean)\n",
    "        @test Statistics.mean(ratio) ≈ 1 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_frac_to_abs_ctratesq\" begin\n",
    "        ratio = (\n",
    "            normalize_frac(pds, dt, N, mean) ./ normalize_abs(pds, dt, N) .* meanrate .^ 2\n",
    "        )\n",
    "        @test Statistics.mean(ratio) ≈ 1 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_total_variance\" begin\n",
    "        vdk_total_variance = sum((lc .- mean) .^ 2)\n",
    "        ratio = Statistics.mean(pds) / vdk_total_variance\n",
    "        @test Statistics.mean(ratio) ≈ 1 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_poisson_level_$(norm)\" for norm in [\"abs\", \"frac\", \"leahy\", \"none\"]\n",
    "        pdsnorm = normalize_periodograms(pds, dt, N; mean_flux=mean, n_ph=nph, norm=norm)\n",
    "        @test Statistics.mean(pdsnorm) ≈ poisson_level(norm; meanrate=meanrate, n_ph=nph) rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_poisson_level_real_$(norm)\" for norm in [\"abs\", \"frac\", \"leahy\", \"none\"]\n",
    "        pdsnorm = normalize_periodograms(pds, dt, N; mean_flux=mean, n_ph=nph, norm=norm, power_type=\"real\")\n",
    "        @test Statistics.mean(pdsnorm) ≈ poisson_level(norm; meanrate=meanrate, n_ph=nph) rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_poisson_level_absolute_$(norm)\" for norm in [\"abs\", \"frac\", \"leahy\", \"none\"]\n",
    "        pdsnorm = normalize_periodograms(pds, dt, N; mean_flux=mean, n_ph=nph, norm=norm, power_type=\"abs\")\n",
    "        @test Statistics.mean(pdsnorm) ≈ poisson_level(norm; meanrate=meanrate, n_ph=nph) rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_normalize_with_variance\" begin\n",
    "        pdsnorm = normalize_periodograms(pds, dt, N; mean_flux=mean, variance=var, norm=\"leahy\")\n",
    "        @test Statistics.mean(pdsnorm) ≈ 2 rtol=0.01\n",
    "    end\n",
    "\n",
    "    @testset \"test_normalize_none\" begin\n",
    "        pdsnorm = normalize_periodograms(pds, dt, N; mean_flux=mean, n_ph=nph, norm=\"none\")\n",
    "        @test Statistics.mean(pdsnorm) ≈ Statistics.mean(pds) rtol=0.01\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d37a0541-86c7-4d02-b247-c2777ef03d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLYING GTI.JL FOR TESTING IT GENRATES OUTPUT OR NOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f3ccb84-17a9-4dac-ba8c-be27c1572776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_indices_of_segment_boundaries_binned (generic function with 1 method)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_total_gti_length(gti::AbstractMatrix{<:Real}; minlen::Real=0.0)\n",
    "    lengths = diff(gti; dims =2)\n",
    "    return sum(x->x > minlen ? x : zero(x), lengths)\n",
    "end\n",
    "\n",
    "function load_gtis(fits_file::String, gtistring::String=\"GTI\")\n",
    "    gti = FITS(fits_file) do lchdulist\n",
    "        gtihdu = lchdulist[gtistring]\n",
    "        get_gti_from_hdu(gtihdu)\n",
    "    end\n",
    "    return gti\n",
    "end\n",
    "\n",
    "function get_gti_from_hdu(gtihdu::TableHDU)\n",
    "\n",
    "    if \"START\" in FITSIO.colnames(gtihdu)\n",
    "        startstr = \"START\"\n",
    "        stopstr = \"STOP\"\n",
    "    else\n",
    "        startstr = \"Start\"\n",
    "        stopstr = \"Stop\"\n",
    "    end\n",
    "\n",
    "    gtistart = read(gtihdu,startstr)\n",
    "    gtistop = read(gtihdu,stopstr)\n",
    "\n",
    "    return mapreduce(permutedims, vcat, \n",
    "    [[a, b] for (a,b) in zip(gtistart, gtistop)])\n",
    "end\n",
    "\n",
    "function check_gtis(gti::AbstractMatrix)\n",
    "\n",
    "    if ndims(gti) != 2 || size(gti,2) != 2\n",
    "        throw(ArgumentError(\"Please check the formatting of the GTIs. \n",
    "       They need to be provided as [[gti00 gti01]; [gti10 gti11]; ...].\"))\n",
    "    end\n",
    "\n",
    "    gti_start = @view gti[:, 1]\n",
    "    gti_end = @view gti[:, 2]\n",
    "\n",
    "    if any(gti_end < gti_start)\n",
    "        throw(ArgumentError(\n",
    "            \"The GTI end times must be larger than the GTI start times.\"\n",
    "        )) \n",
    "    end\n",
    "\n",
    "    if any(@view(gti_start[begin+1:end]) < @view(gti_end[begin:end-1]))\n",
    "        throw(ArgumentError(\n",
    "            \"This GTI has overlaps\"\n",
    "        ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function create_gti_mask(times::AbstractVector{<:Real},gtis::AbstractMatrix{<:Real};\n",
    "                         safe_interval::AbstractVector{<:Real}=[0,0], min_length::Real=0,\n",
    "                         dt::Real = -1, epsilon::Real = 0.001)\n",
    "\n",
    "    if isempty(times)\n",
    "        throw(ArgumentError(\"Passing an empty time array to create_gti_mask\"))\n",
    "    end\n",
    "\n",
    "    check_gtis(gtis)\n",
    "    mask = zeros(Bool,length(times))\n",
    "\n",
    "    if min_length>0\n",
    "        gtis = gtis[min_length .< @view(gtis[:,2]) - @view(gtis[:,1]),:]\n",
    "            \n",
    "        if size(gtis,1) < 1\n",
    "            @warn \"No GTIs longer than min_length $(min_length)\"\n",
    "            return mask, gtis\n",
    "        end\n",
    "    end   \n",
    "\n",
    "    if dt < 0\n",
    "        dt = Statistics.median(diff(times))\n",
    "    end\n",
    "    epsilon_times_dt = epsilon * dt\n",
    "\n",
    "    new_gtis = [[0.0, 0.0] for _ in range(1,size(gtis,1))]\n",
    "    new_gti_mask = zeros(Bool, size(gtis,1))\n",
    "\n",
    "    gti_start = @view gtis[:, 1]\n",
    "    gti_end = @view gtis[:, 2]\n",
    "\n",
    "    for (ig,(limmin,limmax)) in enumerate(zip(gti_start,gti_end))\n",
    "        limmin += safe_interval[1]\n",
    "        limmax -= safe_interval[2]\n",
    "        if limmax - limmin >= min_length\n",
    "            new_gtis[ig][:] .= limmin, limmax\n",
    "            for (i,t) in enumerate(times) \n",
    "                if (limmin + dt / 2 - epsilon_times_dt) <= t <= (limmax - dt / 2 + epsilon_times_dt)\n",
    "                    mask[i] = true\n",
    "                end\n",
    "            end\n",
    "            new_gti_mask[ig] = true\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return mask, mapreduce(permutedims, vcat, keepat!(new_gtis,new_gti_mask))\n",
    "end\n",
    "\n",
    "function create_gti_from_condition(time::AbstractVector{<:Real}, condition::AbstractVector{Bool};\n",
    "    safe_interval::AbstractVector{<:Real}=[0,0], dt::AbstractVector{<:Real}=Float64[])\n",
    "    \n",
    "    if length(time) != length(condition)\n",
    "        throw(ArgumentError(\"The length of the condition and time arrays must be the same.\"))\n",
    "    end\n",
    "\n",
    "    idxs = contiguous_regions(condition)\n",
    "\n",
    "    if isempty(dt)\n",
    "        dt = zero(time) .+ (time[2] .- time[1]) ./ 2\n",
    "    end\n",
    "\n",
    "    gtis = Vector{Float64}[]\n",
    "    for idx in eachrow(idxs)\n",
    "        startidx = idx[1]\n",
    "        stopidx = idx[2] - 1\n",
    "\n",
    "        t0 = time[startidx] - dt[startidx] + safe_interval[1]\n",
    "        t1 = time[stopidx] + dt[stopidx] - safe_interval[2]\n",
    "        if t1 - t0 < 0\n",
    "            continue\n",
    "        end\n",
    "        push!(gtis,[t0, t1])\n",
    "    end\n",
    "    return mapreduce(permutedims, vcat, gtis)\n",
    "end\n",
    "\n",
    "function operations_on_gtis(gti_list::AbstractVector{<:AbstractMatrix{T}}, \n",
    "                            operation::Function) where {T<:Real}\n",
    "\n",
    "    required_interval = nothing\n",
    "\n",
    "    for gti in gti_list\n",
    "        check_gtis(gti)\n",
    "\n",
    "        combined_gti = Interval{T}[]\n",
    "        for ig in eachrow(gti)\n",
    "            push!(combined_gti,Interval{Closed,Open}(ig[1],ig[2]))\n",
    "        end\n",
    "        if isnothing(required_interval)\n",
    "            required_interval = IntervalSet(combined_gti)\n",
    "        else\n",
    "            required_interval = operation(required_interval, IntervalSet(combined_gti))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    final_gti = Vector{T}[]\n",
    "\n",
    "    for interval in required_interval.items\n",
    "        push!(final_gti, [first(interval), last(interval)])\n",
    "    end\n",
    "\n",
    "    return mapreduce(permutedims, vcat, final_gti)\n",
    "end\n",
    "\n",
    "function get_btis(gtis::AbstractMatrix{<:Real})\n",
    "    if isempty(gtis)\n",
    "        throw(ArgumentError(\"Empty GTI and no valid start_time and stop_time\"))\n",
    "    end\n",
    "    return get_btis(gtis, gtis[1,1], gtis[end,2])\n",
    "end\n",
    "\n",
    "function get_btis(gtis::AbstractMatrix{T}, start_time, stop_time) where {T<:Real}\n",
    "    if isempty(gtis)\n",
    "        return T[start_time stop_time]\n",
    "    end\n",
    "    check_gtis(gtis)\n",
    "\n",
    "    total_interval = Interval{T, Closed, Open}[Interval{T, Closed, Open}(start_time, stop_time)]\n",
    "    total_interval_set = IntervalSet(total_interval)\n",
    "\n",
    "    gti_interval = Interval{T, Closed, Open}[]\n",
    "    for ig in eachrow(gtis)\n",
    "        push!(gti_interval,Interval{T, Closed, Open}(ig[1],ig[2]))\n",
    "    end\n",
    "    gti_interval_set = IntervalSet(gti_interval)\n",
    "\n",
    "    bti_interval_set = setdiff(total_interval_set, gti_interval_set)\n",
    "\n",
    "    btis = Vector{T}[]\n",
    "\n",
    "    for interval in bti_interval_set.items\n",
    "        push!(btis, [first(interval), last(interval)])\n",
    "    end\n",
    "\n",
    "    return mapreduce(permutedims, vcat, btis)\n",
    "end\n",
    "\n",
    "function time_intervals_from_gtis(gtis::AbstractMatrix{<:Real}, segment_size::Real;\n",
    "                                  fraction_step::Real=1, epsilon::Real=1e-5)  \n",
    "    spectrum_start_times = Float64[]\n",
    "\n",
    "    gti_low = @view gtis[:,1]\n",
    "    gti_up = @view gtis[:,2]\n",
    "\n",
    "    for (g1,g2) in zip(gti_low,gti_up)\n",
    "        if g2 - g1 + epsilon < segment_size\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        newtimes = range(g1, g2 - segment_size + epsilon, step = segment_size* fraction_step)\n",
    "        append!(spectrum_start_times,newtimes)\n",
    "    end\n",
    "    return spectrum_start_times, spectrum_start_times .+ segment_size\n",
    "end\n",
    "\n",
    "function calculate_segment_bin_start(startbin::Integer, stopbin::Integer,\n",
    "                                     nbin::Integer; fraction_step::Real=1)\n",
    "    st = floor.(range(startbin, stopbin, step=Int(nbin * fraction_step)))\n",
    "    if st[end] == stopbin\n",
    "        pop!(st)\n",
    "    end\n",
    "    if st[end] + nbin > stopbin\n",
    "        pop!(st)\n",
    "    end\n",
    "    return st\n",
    "end\n",
    "\n",
    "function bin_intervals_from_gtis(gtis::AbstractMatrix{<:Real}, segment_size::Real,\n",
    "                                 time::AbstractVector{<:Real}; dt=nothing, \n",
    "                                 fraction_step::Real=1, epsilon::Real=0.001)\n",
    "    if isnothing(dt)\n",
    "        dt = Statistics.median(diff(time))\n",
    "    end\n",
    "\n",
    "    epsilon_times_dt = epsilon * dt\n",
    "    nbin = round(Int, segment_size / dt)\n",
    "\n",
    "    spectrum_start_bins = Int[]\n",
    "\n",
    "    gti_low = @view(gtis[:, 1]) .+ (dt ./ 2 .- epsilon_times_dt)\n",
    "    gti_up = @view(gtis[:, 2]) .- (dt ./ 2 .- epsilon_times_dt)\n",
    "\n",
    "    for (g0, g1) in zip(gti_low, gti_up)\n",
    "        if (g1 - g0 .+ (dt + epsilon_times_dt)) < segment_size\n",
    "            continue\n",
    "        end\n",
    "        startbin, stopbin = searchsortedfirst.(Ref(time), [g0, g1])\n",
    "        startbin -= 1\n",
    "        if stopbin > length(time)\n",
    "            stopbin = length(time)\n",
    "        end\n",
    "\n",
    "        if time[startbin+1] < g0\n",
    "            startbin += 1\n",
    "        end\n",
    "        # Would be g[1] - dt/2, but stopbin is the end of an interval\n",
    "        # so one has to add one bin\n",
    "        if time[stopbin] > g1\n",
    "            stopbin -= 1\n",
    "        end\n",
    "\n",
    "        newbins = calculate_segment_bin_start(\n",
    "            startbin, stopbin, nbin, fraction_step=fraction_step)\n",
    "        \n",
    "        append!(spectrum_start_bins,newbins)\n",
    "    end \n",
    "    return spectrum_start_bins, spectrum_start_bins.+nbin \n",
    "end\n",
    "\n",
    "@resumable function generate_indices_of_segment_boundaries_unbinned(times::AbstractVector{<:Real},\n",
    "                                                                    gti::AbstractMatrix{<:Real},\n",
    "                                                                    segment_size::Real)\n",
    "    start, stop = time_intervals_from_gtis(gti, segment_size)\n",
    "\n",
    "    startidx = searchsortedfirst.(Ref(times), start)\n",
    "    stopidx = searchsortedfirst.(Ref(times), stop)\n",
    "\n",
    "    for (s, e, idx0, idx1) in zip(start, stop, startidx, stopidx)\n",
    "        @yield s, e, idx0, idx1\n",
    "    end\n",
    "end\n",
    "\n",
    "@resumable function generate_indices_of_segment_boundaries_binned(times::AbstractVector{<:Real},\n",
    "                                                                  gti::AbstractMatrix{<:Real},\n",
    "                                                                  segment_size::Real; dt=nothing)\n",
    "    startidx, stopidx = bin_intervals_from_gtis(gti, segment_size, times;\n",
    "                                                dt=dt)\n",
    "\n",
    "    if isnothing(dt)\n",
    "        dt = 0\n",
    "    end\n",
    "    for (idx0, idx1) in zip(startidx, stopidx)\n",
    "        @yield times[idx0+1] - dt / 2, times[min(idx1, length(times) - 1)] - dt / 2,idx0, idx1\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f6bb8124-a247-47bd-bf8b-b386f04498f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\asus4\\Desktop\\julia_notebokk\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a3c13759-b97b-440a-a8ca-29f462038871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FITS file: 1.fits\n",
      "Available HDUs in 1.fits:\n",
      "HDU[1]: File: 1.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Float32 (physical: Int16)\n",
      "Datasize: (512, 512)\n",
      "Image HDU found in 1.fits at HDU[1], reading data...\n",
      "512, 512)a loaded. Shape: (\n",
      "CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 1.fits\n",
      "\n",
      "Processing FITS file: 2.fits\n",
      "Available HDUs in 2.fits:\n",
      "HDU[1]: File: 2.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Int16\n",
      "Datasize: (512, 512)\n",
      "File: 2.fits\n",
      "HDU: 2 (name=LS3)\n",
      "Type: Table\n",
      "Rows: 4\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "HDU[3]: File: 2.fits\n",
      "HDU: 3 (name=MS3)\n",
      "Type: Table\n",
      "Rows: 12\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "Image HDU found in 2.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "HDU[2] in 2.fits is not an image.\n",
      "HDU[3] in 2.fits is not an image.\n",
      "Error computing spectral metrics for 2.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 2.fits\n",
      "\n",
      "Processing FITS file: 3.fits\n",
      "Available HDUs in 3.fits:\n",
      "HDU[1]: File: 3.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Int16\n",
      "Datasize: (512, 512)\n",
      "HDU[2]: File: 3.fits\n",
      "HDU: 2 (name=LS2)\n",
      "Type: Table\n",
      "Rows: 6\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "HDU[3]: File: 3.fits\n",
      "HDU: 3 (name=MS2)\n",
      "Type: Table\n",
      "Rows: 17\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "Image HDU found in 3.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "HDU[2] in 3.fits is not an image.\n",
      "HDU[3] in 3.fits is not an image.\n",
      "Error computing spectral metrics for 3.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 3.fits\n",
      "\n",
      "Processing FITS file: 4.fits\n",
      "Available HDUs in 4.fits:\n",
      "HDU[1]: File: 4.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Int16\n",
      "Datasize: (512, 512)\n",
      "HDU[2]: File: 4.fits\n",
      "HDU: 2 (name=LS1)\n",
      "Type: Table\n",
      "Rows: 8\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "HDU[3]: File: 4.fits\n",
      "HDU: 3 (name=MS1)\n",
      "Type: Table\n",
      "Rows: 18\n",
      "Columns: Name      Size  Type     TFORM  \n",
      "         SRC_NR          Int16    1I     \n",
      "         LEV1_X          Float32  1E     \n",
      "         LEV1_Y          Float32  1E     \n",
      "         NET_CTS         Float32  1E     \n",
      "         BKG_CTS         Float32  1E     \n",
      "         S_LIKE          Float32  1E     \n",
      "         C_SIZE          Int16    1I     \n",
      "         NN_DIST         Float32  1E     \n",
      "         RIB_DIST        Float32  1E     \n",
      "Image HDU found in 4.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "HDU[2] in 4.fits is not an image.\n",
      "HDU[3] in 4.fits is not an image.\n",
      "Error computing spectral metrics for 4.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 4.fits\n",
      "\n",
      "Processing FITS file: 5.fits\n",
      "Available HDUs in 5.fits:\n",
      "HDU[1]: File: 5.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Float32 (physical: Int16)\n",
      "Datasize: (512, 512)\n",
      "Image HDU found in 5.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "Error computing spectral metrics for 5.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 5.fits\n",
      "\n",
      "Processing FITS file: 6.fits\n",
      "Available HDUs in 6.fits:\n",
      "HDU[1]: File: 6.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Float32 (physical: Int16)\n",
      "Datasize: (512, 512)\n",
      "Image HDU found in 6.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "Error computing spectral metrics for 6.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 6.fits\n",
      "\n",
      "Processing FITS file: 7.fits\n",
      "Available HDUs in 7.fits:\n",
      "HDU[1]: File: 7.fits\n",
      "HDU: 1\n",
      "Mode: read-only\n",
      "Type: Image\n",
      "Datatype: Float32 (physical: Int16)\n",
      "Datasize: (512, 512)\n",
      "Image HDU found in 7.fits at HDU[1], reading data...\n",
      "Image data loaded. Shape: (512, 512)\n",
      "Error computing spectral metrics for 7.fits: CFITSIO.CFITSIOError{Nothing}(nothing, 301, \"illegal HDU number\", \"\")\n",
      "Finished processing 7.fits\n",
      "\n",
      "All FITS files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "using Downloads, FITSIO, Plots, Test\n",
    "\n",
    "\n",
    "# List of FITS file names\n",
    "fits_files = [\"1.fits\", \"2.fits\", \"3.fits\", \"4.fits\", \"5.fits\", \"6.fits\", \"7.fits\"]\n",
    "\n",
    "# Loop through each FITS file\n",
    "for fits_file in fits_files\n",
    "    println(\"Processing FITS file: $fits_file\")\n",
    "\n",
    "    if !isfile(fits_file)\n",
    "        println(\"File not found: $fits_file. Skipping...\")\n",
    "        continue\n",
    "    end\n",
    "\n",
    "    # Step 1: Open the FITS file\n",
    "    fits = FITS(fits_file, \"r\")  # Open in read mode\n",
    "\n",
    "    # Step 2: List available HDUs\n",
    "    println(\"Available HDUs in $fits_file:\")\n",
    "    hdu_count = length(fits)  # Number of HDUs\n",
    "    for i in 1:hdu_count\n",
    "        println(\"HDU[$i]: \", fits[i])\n",
    "    end\n",
    "\n",
    "    # Step 3: Check for image HDUs\n",
    "    for i in 1:hdu_count\n",
    "        hdu = fits[i]\n",
    "        if hdu isa ImageHDU\n",
    "            println(\"Image HDU found in $fits_file at HDU[$i], reading data...\")\n",
    "            image_data = read(hdu)\n",
    "            println(\"Image data loaded. Shape: \", size(image_data))\n",
    "\n",
    "            # Step 4: Plot image data\n",
    "            heatmap(image_data, title=\"FITS Image from $fits_file - HDU[$i]\", color=:viridis)\n",
    "        else\n",
    "            println(\"HDU[$i] in $fits_file is not an image.\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Step 4: Compute spectral analysis metrics\n",
    "    try\n",
    "        times, gti = load_gtis(fits_file)\n",
    "\n",
    "        if isempty(gti)\n",
    "            println(\"No GTI data found for $fits_file, skipping spectral analysis.\")\n",
    "        else\n",
    "            segment_size = get_total_gti_length(gti)\n",
    "            dt = 0.01  # Example time resolution\n",
    "\n",
    "            avg_pds = avg_pds_from_events(times, gti, segment_size, dt, norm=\"frac\")\n",
    "            avg_cs = avg_cs_from_events(times, gti, segment_size, dt)\n",
    "\n",
    "            fft_bins = positive_fft_bins(avg_pds)\n",
    "            poisson_lvl = poisson_level(avg_pds)\n",
    "            norm_pds = normalize_periodograms(avg_pds, method=\"leahy\")\n",
    "            bias = bias_term(avg_cs)\n",
    "            raw_coh = raw_coherence(avg_cs, avg_pds)\n",
    "            intrinsic_coh = estimate_intrinsic_coherence(avg_cs, avg_pds)\n",
    "            cs_error = error_on_averaged_cross_spectrum(avg_cs)\n",
    "            avg_ctrate = get_average_ctrate(times)\n",
    "            flux_iterable = get_flux_iterable_from_segments(times, gti, segment_size)\n",
    "\n",
    "            println(\"Computed Spectral Analysis Metrics for $fits_file\")\n",
    "        end\n",
    "    catch e\n",
    "        println(\"Error computing spectral metrics for $fits_file: \", e)\n",
    "    end\n",
    "\n",
    "    # Step 5: Close the FITS file\n",
    "    close(fits)\n",
    "    println(\"Finished processing $fits_file\\n\")\n",
    "end\n",
    "\n",
    "println(\"All FITS files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761d9cc-8020-4843-bcd8-e62cb58637d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
