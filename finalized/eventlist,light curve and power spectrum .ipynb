{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ace9ffc-83ee-4c57-967d-2532ed039db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validate"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using FITSIO\n",
    "\"\"\"\n",
    "Abstract type for all event list implementations\n",
    "\"\"\"\n",
    "abstract type AbstractEventList{T} end\n",
    "\n",
    "\"\"\"\n",
    "    DictMetadata\n",
    "\n",
    "A structure containing metadata from FITS file headers.\n",
    "\n",
    "## Fields\n",
    "\n",
    "- `headers::Vector{Dict{String,Any}}`: A vector of dictionaries containing header information from each HDU.\n",
    "\"\"\"\n",
    "struct DictMetadata\n",
    "    headers::Vector{Dict{String,Any}}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    EventList{T} <: AbstractEventList{T}\n",
    "\n",
    "A structure containing event data from a FITS file.\n",
    "\n",
    "## Fields\n",
    "\n",
    "- `filename::String`: Path to the source FITS file.\n",
    "- `times::Vector{T}`: Vector of event times.\n",
    "- `energies::Vector{T}`: Vector of event energies.\n",
    "- `metadata::DictMetadata`: Metadata information extracted from the FITS file headers.\n",
    "\"\"\"\n",
    "struct EventList{T} <: AbstractEventList{T}\n",
    "    filename::String\n",
    "    times::Vector{T}\n",
    "    energies::Vector{T}\n",
    "    metadata::DictMetadata\n",
    "end\n",
    "\n",
    "times(ev::EventList) = ev.times\n",
    "energies(ev::EventList) = ev.energies\n",
    "\n",
    "\"\"\"\n",
    "    readevents(path; T = Float64)\n",
    "\n",
    "Read event data from a FITS file into an EventList structure.\n",
    "\n",
    "## Arguments\n",
    "- `path::String`: Path to the FITS file\n",
    "- `T::Type=Float64`: Numeric type for the data\n",
    "\n",
    "## Returns\n",
    "- [`EventList`](@ref) containing the extracted data\n",
    "\n",
    "## Notes\n",
    "\n",
    "The function extracts `TIME` and `ENERGY` columns from any TableHDU in the FITS\n",
    "file. All headers from each HDU are collected into the metadata field. It will\n",
    "use the first occurrence of complete event data (both TIME and ENERGY columns)\n",
    "found in the file.\n",
    "\"\"\"\n",
    "function readevents(path; T = Float64)\n",
    "    headers = Dict{String,Any}[]\n",
    "    times = T[]\n",
    "    energies = T[]\n",
    "\n",
    "    FITS(path, \"r\") do f\n",
    "        for i = 1:length(f)  # Iterate over HDUs\n",
    "            hdu = f[i]\n",
    "            # Always collect headers from all extensions\n",
    "            header_dict = Dict{String,Any}()\n",
    "            for key in keys(read_header(hdu))\n",
    "                header_dict[string(key)] = read_header(hdu)[key]\n",
    "            end\n",
    "            push!(headers, header_dict)\n",
    "\n",
    "            # Check if the HDU is a table\n",
    "            if isa(hdu, TableHDU)\n",
    "                colnames = FITSIO.colnames(hdu)\n",
    "\n",
    "                # Read TIME and ENERGY data if columns exist and vectors are empty\n",
    "                if isempty(times) && (\"TIME\" in colnames)\n",
    "                    times = convert(Vector{T}, read(hdu, \"TIME\"))\n",
    "                end\n",
    "                if isempty(energies) && (\"ENERGY\" in colnames)\n",
    "                    energies = convert(Vector{T}, read(hdu, \"ENERGY\"))\n",
    "                end\n",
    "\n",
    "                # If we found both time and energy data, we can return\n",
    "                if !isempty(times) && !isempty(energies)\n",
    "                    @info \"Found complete event data in extension $(i) of $(path)\"\n",
    "                    metadata = DictMetadata(headers)\n",
    "                    return EventList{T}(path, times, energies, metadata)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if isempty(times)\n",
    "        @warn \"No TIME data found in FITS file $(path). Time series analysis will not be possible.\"\n",
    "    end\n",
    "    if isempty(energies)\n",
    "        @warn \"No ENERGY data found in FITS file $(path). Energy spectrum analysis will not be possible.\"\n",
    "    end\n",
    "\n",
    "    metadata = DictMetadata(headers)\n",
    "    return EventList{T}(path, times, energies, metadata)\n",
    "end\n",
    "\n",
    "Base.length(ev::AbstractEventList) = length(times(ev))\n",
    "Base.size(ev::AbstractEventList) = (length(ev),)\n",
    "Base.getindex(ev::EventList, i) = (ev.times[i], ev.energies[i])\n",
    "\n",
    "function Base.show(io::IO, ev::EventList{T}) where T\n",
    "    print(io, \"EventList{$T}(n=$(length(ev)), file=$(ev.filename))\")\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    validate(events::AbstractEventList)\n",
    "\n",
    "Validate the event list structure.\n",
    "\n",
    "## Returns\n",
    "- `true` if valid, throws ArgumentError otherwise\n",
    "\"\"\"\n",
    "function validate(events::AbstractEventList)\n",
    "    evt_times = times(events)\n",
    "    if !issorted(evt_times)\n",
    "        throw(ArgumentError(\"Event times must be sorted in ascending order\"))\n",
    "    end\n",
    "    if length(evt_times) == 0\n",
    "        throw(ArgumentError(\"Event list is empty\"))\n",
    "    end\n",
    "    return true\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad18ff7-baf1-430b-9793-f94ccda14faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_TyeKCZ\\sample.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_jn6ERa\\sample_float32.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_jn6ERa\\sample_float32.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_j9ejso\\sample_multi_hdu.fits\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNo ENERGY data found in FITS file data\\monol_testA.evt. Energy spectrum analysis will not be possible.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Main In[15]:102\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:   | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "EventList Tests | \u001b[32m  39  \u001b[39m\u001b[36m   39  \u001b[39m\u001b[0m1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_79JB99\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_79JB99\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_79JB99\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_79JB99\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_jl25kQ\\sample_validate.fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"EventList Tests\", Any[Test.DefaultTestSet(\"Sample FITS file creation\", Any[], 6, false, false, true, 1.743334756737e9, 1.74333475718e9, false, \"In[16]\"), Test.DefaultTestSet(\"Different data types\", Any[], 4, false, false, true, 1.74333475718e9, 1.743334757229e9, false, \"In[16]\"), Test.DefaultTestSet(\"Missing columns\", Any[], 6, false, false, true, 1.743334757229e9, 1.743334757517e9, false, \"In[16]\"), Test.DefaultTestSet(\"Multiple HDUs\", Any[], 4, false, false, true, 1.743334757517e9, 1.743334757538e9, false, \"In[16]\"), Test.DefaultTestSet(\"test monol_testA.evt\", Any[], 3, false, false, true, 1.743334757538e9, 1.743334757544e9, false, \"In[16]\"), Test.DefaultTestSet(\"Error handling\", Any[], 2, false, false, true, 1.743334757544e9, 1.743334757815e9, false, \"In[16]\"), Test.DefaultTestSet(\"EventList Struct Type Checks\", Any[Test.DefaultTestSet(\"Type Parametric Struct Tests\", Any[], 6, false, false, true, 1.743334757817e9, 1.743334757836e9, false, \"In[16]\"), Test.DefaultTestSet(\"Struct Field Type Checks\", Any[], 5, false, false, true, 1.743334757836e9, 1.743334757839e9, false, \"In[16]\")], 0, false, false, true, 1.743334757815e9, 1.743334757839e9, false, \"In[16]\"), Test.DefaultTestSet(\"Validation Tests\", Any[], 3, false, false, true, 1.743334757839e9, 1.743334757888e9, false, \"In[16]\")], 0, false, false, true, 1.743334756737e9, 1.743334757888e9, false, \"In[16]\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test\n",
    "@testset \"EventList Tests\" begin\n",
    "    # Test 1: Create a sample FITS file for testing\n",
    "    @testset \"Sample FITS file creation\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample.fits\")\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])  # Empty primary array\n",
    "        # Create a binary table HDU with TIME and ENERGY columns\n",
    "        times = Float64[1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 15.0, 25.0, 30.0]\n",
    "        # Add a binary table extension\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "\n",
    "        @test isfile(sample_file)\n",
    "\n",
    "        # Test reading the sample file\n",
    "        data = readevents(sample_file)\n",
    "        @test data.filename == sample_file\n",
    "        @test length(data.times) == 5\n",
    "        @test length(data.energies) == 5\n",
    "        @test eltype(data.times) == Float64\n",
    "        @test eltype(data.energies) == Float64\n",
    "    end\n",
    "\n",
    "    # Test 2: Test with different data types\n",
    "    @testset \"Different data types\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_float32.fits\")\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        # Create data\n",
    "        times = Float64[1.0, 2.0, 3.0]\n",
    "        energies = Float64[10.0, 20.0, 30.0]\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        # Test with Float32\n",
    "        data_f32 = readevents(sample_file, T = Float32)\n",
    "        @test eltype(data_f32.times) == Float32\n",
    "        @test eltype(data_f32.energies) == Float32\n",
    "        # Test with Int64\n",
    "        data_i64 = readevents(sample_file, T = Int64)\n",
    "        @test eltype(data_i64.times) == Int64\n",
    "        @test eltype(data_i64.energies) == Int64\n",
    "    end\n",
    "\n",
    "    # Test 3: Missing Columns\n",
    "    @testset \"Missing columns\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_no_energy.fits\")\n",
    "        # Create a sample FITS file with only TIME column\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        times = Float64[1.0, 2.0, 3.0]\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        local data\n",
    "        @test_logs (:warn, \"No ENERGY data found in FITS file $(sample_file). Energy spectrum analysis will not be possible.\") begin\n",
    "            data = readevents(sample_file)\n",
    "        end\n",
    "        @test length(data.times) == 3\n",
    "        @test length(data.energies) == 0\n",
    "\n",
    "        # Create a file with only ENERGY column\n",
    "        sample_file2 = joinpath(test_dir, \"sample_no_time.fits\")\n",
    "        f = FITS(sample_file2, \"w\")\n",
    "        write(f, Int[])  # Empty primary array\n",
    "        energies = Float64[10.0, 20.0, 30.0]\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        local data2\n",
    "        @test_logs (:warn, \"No TIME data found in FITS file $(sample_file2). Time series analysis will not be possible.\") begin\n",
    "            data2 = readevents(sample_file2)\n",
    "        end\n",
    "        @test length(data2.times) == 0  # No TIME column\n",
    "        @test length(data2.energies) == 3\n",
    "    end\n",
    "\n",
    "    # Test 4: Multiple HDUs\n",
    "    @testset \"Multiple HDUs\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_multi_hdu.fits\")\n",
    "        # Create a sample FITS file with multiple HDUs\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        times1 = Float64[1.0, 2.0, 3.0]\n",
    "        energies1 = Float64[10.0, 20.0, 30.0]\n",
    "        table1 = Dict{String,Array}()\n",
    "        table1[\"TIME\"] = times1\n",
    "        table1[\"ENERGY\"] = energies1\n",
    "        write(f, table1)\n",
    "        # Second table HDU (with OTHER column)\n",
    "        other_data = Float64[100.0, 200.0, 300.0]\n",
    "        table2 = Dict{String,Array}()\n",
    "        table2[\"OTHER\"] = other_data\n",
    "        write(f, table2)\n",
    "        # Third table HDU (with TIME only)\n",
    "        times3 = Float64[4.0, 5.0, 6.0]\n",
    "        table3 = Dict{String,Array}()\n",
    "        table3[\"TIME\"] = times3\n",
    "        write(f, table3)\n",
    "        close(f)\n",
    "        \n",
    "        # Diagnostic printing\n",
    "        data = readevents(sample_file)\n",
    "        @test length(data.metadata.headers) >= 2  # At least primary and first extension\n",
    "        @test length(data.metadata.headers) <= 4  # No more than primary + 3 extensions\n",
    "        # Should read the first HDU with both TIME and ENERGY\n",
    "        @test length(data.times) == 3\n",
    "        @test length(data.energies) == 3\n",
    "    end\n",
    "\n",
    "    # Test 5: Test with monol_testA.evt\n",
    "    @testset \"test monol_testA.evt\" begin\n",
    "        test_filepath = joinpath(\"data\", \"monol_testA.evt\")\n",
    "        if isfile(test_filepath)\n",
    "            data = readevents(test_filepath)\n",
    "            @test data.filename == test_filepath\n",
    "            @test length(data.metadata.headers) > 0\n",
    "            @test !isempty(data.times)\n",
    "        else\n",
    "            @info \"Test file '$(test_filepath)' not found. Skipping this test.\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Test 6: Error handling\n",
    "    @testset \"Error handling\" begin\n",
    "        # Test with non-existent file - using a more generic approach\n",
    "        @test_throws Exception readevents(\"non_existent_file.fits\")\n",
    "\n",
    "        # Test with invalid FITS file\n",
    "        invalid_file = tempname()\n",
    "        open(invalid_file, \"w\") do io\n",
    "            write(io, \"This is not a FITS file\")\n",
    "        end\n",
    "        @test_throws Exception readevents(invalid_file)\n",
    "    end\n",
    "\n",
    "    # Test 7: Struct Type Validation\n",
    "    @testset \"EventList Struct Type Checks\" begin\n",
    "        # Create a sample FITS file for type testing\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_types.fits\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])  # Empty primary array\n",
    "        \n",
    "        # Create test data\n",
    "        times = Float64[1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 15.0, 25.0, 30.0]\n",
    "        \n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "\n",
    "        # Test type-specific instantiations\n",
    "        @testset \"Type Parametric Struct Tests\" begin\n",
    "            # Test Float64 EventList\n",
    "            data_f64 = readevents(sample_file, T = Float64)\n",
    "            @test isa(data_f64, EventList{Float64})\n",
    "            @test typeof(data_f64) == EventList{Float64}\n",
    "            \n",
    "            # Test Float32 EventList\n",
    "            data_f32 = readevents(sample_file, T = Float32)\n",
    "            @test isa(data_f32, EventList{Float32})\n",
    "            @test typeof(data_f32) == EventList{Float32}\n",
    "            \n",
    "            # Test Int64 EventList\n",
    "            data_i64 = readevents(sample_file, T = Int64)\n",
    "            @test isa(data_i64, EventList{Int64})\n",
    "            @test typeof(data_i64) == EventList{Int64}\n",
    "        end\n",
    "\n",
    "        # Test struct field types\n",
    "        @testset \"Struct Field Type Checks\" begin\n",
    "            data = readevents(sample_file)\n",
    "            \n",
    "            # Check filename type\n",
    "            @test isa(data.filename, String)\n",
    "            \n",
    "            # Check times and energies vector types\n",
    "            @test isa(data.times, Vector{Float64})\n",
    "            @test isa(data.energies, Vector{Float64})\n",
    "            \n",
    "            # Check metadata type\n",
    "            @test isa(data.metadata, DictMetadata)\n",
    "            @test isa(data.metadata.headers, Vector{Dict{String,Any}})\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Test 8: Validation Function\n",
    "    @testset \"Validation Tests\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_validate.fits\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        times = Float64[1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 15.0, 25.0, 30.0]\n",
    "        \n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "\n",
    "        data = readevents(sample_file)\n",
    "        \n",
    "        # Test successful validation\n",
    "        @test validate(data) == true\n",
    "\n",
    "        # Test with unsorted times\n",
    "        unsorted_times = Float64[3.0, 1.0, 2.0]\n",
    "        unsorted_energies = Float64[30.0, 10.0, 20.0]\n",
    "        unsorted_data = EventList{Float64}(sample_file, unsorted_times, unsorted_energies, \n",
    "                                           DictMetadata([Dict{String,Any}()]))\n",
    "        @test_throws ArgumentError validate(unsorted_data)\n",
    "\n",
    "        # Test with empty event list\n",
    "        empty_data = EventList{Float64}(sample_file, Float64[], Float64[], \n",
    "                                        DictMetadata([Dict{String,Any}()]))\n",
    "        @test_throws ArgumentError validate(empty_data)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f32edcb-217d-404f-afb3-e654daa2460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    LightCurve{T}\n",
    "\n",
    "A structure containing lightcurve data from a FITS file.\n",
    "\n",
    "## Fields\n",
    "\n",
    "- `timebins::Vector{T}`: Vector of time bins.\n",
    "- `counts::Vector{Int}`: Vector of event counts in each time bin.\n",
    "- `count_error::Vector{T}`: Vector of errors on the counts in each time bin.\n",
    "- `err_method::Symbol`: Method used for computing the errors.\n",
    "\"\"\"\n",
    "struct LightCurve{T}\n",
    "    timebins::Vector{T}\n",
    "    counts::Vector{Int}\n",
    "    count_error::Vector{T}\n",
    "    err_method::Symbol\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "   create_lightcurve(eventlist::EventList{T}, binsize::Real; err_method::Symbol=:poisson) -> LightCurve{T}\n",
    "\n",
    "Create a lightcurve from an event list.\n",
    "\n",
    "## Arguments\n",
    "- `eventlist::EventList{T}`: Event list containing the event data.\n",
    "- `binsize::Real`: Size of the time bins.\n",
    "\n",
    "## Keyword Arguments\n",
    "- `err_method::Symbol=:poisson`: Method for computing the errors.\n",
    "\n",
    "## Returns\n",
    "- [`LightCurve`](@ref) containing the binned data.\n",
    "\"\"\"\n",
    "function create_lightcurve(eventlist::EventList{T}, binsize::Real; err_method::Symbol=:poisson) where T\n",
    "    # Validate error method first\n",
    "    if err_method != :poisson\n",
    "        throw(ArgumentError(\"Unsupported error computation method: $err_method\"))\n",
    "    end\n",
    "\n",
    "    # Convert binsize to the same type as the event times\n",
    "    binsize_t = convert(T, binsize)\n",
    "    \n",
    "    times = eventlist.times\n",
    "    min_time = minimum(times)\n",
    "    max_time = maximum(times)\n",
    "    \n",
    "    # Calculate number of bins needed\n",
    "    time_range = max_time - min_time\n",
    "    nbins = floor(Int, time_range / binsize_t)\n",
    "    \n",
    "    # If there's any remainder or if max_time falls exactly on a bin edge, add another bin\n",
    "    if !isapprox(mod(time_range, binsize_t), zero(T)) || isapprox(mod(max_time - min_time, binsize_t), zero(T))\n",
    "        nbins += 1\n",
    "    end\n",
    "    \n",
    "    # Create arrays\n",
    "    counts = zeros(Int, nbins)\n",
    "    count_error = Vector{T}(undef, nbins)\n",
    "    timebins = Vector{T}(undef, nbins + 1)\n",
    "    \n",
    "    # Create bin edges\n",
    "    for i in 0:nbins\n",
    "        timebins[i + 1] = min_time + (i * binsize_t)\n",
    "    end\n",
    "    \n",
    "    # Bin the events using count() for better performance\n",
    "    for i in 1:nbins\n",
    "        bin_start = timebins[i]\n",
    "        bin_end = timebins[i + 1]\n",
    "        counts[i] = count(x -> bin_start <= x < bin_end, times)\n",
    "    end\n",
    "    \n",
    "    # Calculate Poisson errors\n",
    "    for i in 1:nbins\n",
    "        count_error[i] = convert(T, sqrt(counts[i]))\n",
    "    end\n",
    "    \n",
    "    return LightCurve{T}(timebins, counts, count_error, err_method)\n",
    "end\n",
    "# Show method for pretty printing\n",
    "function Base.show(io::IO, lc::LightCurve{T}) where T\n",
    "    nbins = length(lc.counts)\n",
    "    binsize = lc.timebins[2] - lc.timebins[1]\n",
    "    print(io, \"LightCurve{$T}(n=$nbins, binsize=$binsize)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d18dff2-79cc-4beb-b77f-b6aaf0309fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_z8pN68\\sample.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_2V7d6T\\sample_bin_sizes.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_nb0EeP\\sample_error_methods.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_sPiuVV\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_sPiuVV\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_sPiuVV\\sample_types.fits\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFound complete event data in extension 2 of C:\\Users\\asus4\\AppData\\Local\\Temp\\jl_sPiuVV\\sample_types.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:    | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "LightCurve Tests | \u001b[32m  47  \u001b[39m\u001b[36m   47  \u001b[39m\u001b[0m0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"LightCurve Tests\", Any[Test.DefaultTestSet(\"Lightcurve creation\", Any[], 13, false, false, true, 1.743334758074e9, 1.743334758331e9, false, \"In[18]\"), Test.DefaultTestSet(\"Different bin sizes\", Any[], 12, false, false, true, 1.743334758331e9, 1.743334758352e9, false, \"In[18]\"), Test.DefaultTestSet(\"Error computation methods\", Any[], 1, false, false, true, 1.743334758352e9, 1.74333475837e9, false, \"In[18]\"), Test.DefaultTestSet(\"LightCurve Struct Type Checks\", Any[Test.DefaultTestSet(\"Type Parametric Struct Tests\", Any[], 12, false, false, true, 1.743334758376e9, 1.743334758854e9, false, \"In[18]\"), Test.DefaultTestSet(\"Struct Field Type Checks\", Any[], 9, false, false, true, 1.743334758854e9, 1.743334758856e9, false, \"In[18]\")], 0, false, false, true, 1.74333475837e9, 1.743334758856e9, false, \"In[18]\")], 0, false, false, true, 1.743334758074e9, 1.743334758856e9, false, \"In[18]\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test\n",
    "using FITSIO\n",
    "\n",
    "@testset \"LightCurve Tests\" begin\n",
    "    # Test 1: Create a lightcurve from a sample EventList\n",
    "    @testset \"Lightcurve creation\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample.fits\")\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])  # Empty primary array\n",
    "        \n",
    "        # Create a binary table HDU with TIME and ENERGY columns\n",
    "        times = Float64[1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 15.0, 25.0, 30.0]\n",
    "        \n",
    "        # Add a binary table extension\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        \n",
    "        @test isfile(sample_file)\n",
    "        \n",
    "        # Test reading the sample file\n",
    "        data = readevents(sample_file)\n",
    "        @test data.filename == sample_file\n",
    "        @test length(data.times) == 5\n",
    "        @test length(data.energies) == 5\n",
    "        @test eltype(data.times) == Float64\n",
    "        @test eltype(data.energies) == Float64\n",
    "        \n",
    "        # Create a lightcurve from the event data\n",
    "        lc =create_lightcurve(data, 1.0)\n",
    "        \n",
    "        # Basic size checks\n",
    "        @test length(lc.timebins) == 6  # 5 bins + 1 endpoint\n",
    "        @test length(lc.counts) == 5\n",
    "        \n",
    "        # Time bin checks\n",
    "        @test lc.timebins[1] ≈ 1.0\n",
    "        @test lc.timebins[end] ≈ 6.0\n",
    "        \n",
    "        # Count checks - each bin should have 1 count\n",
    "        @test all(lc.counts .== 1)\n",
    "        \n",
    "        # Error checks - since each bin has 1 count, errors should be sqrt(1)\n",
    "        @test all(lc.count_error .≈ fill(sqrt(1.0), 5))\n",
    "        \n",
    "        # Method check\n",
    "        @test lc.err_method == :poisson\n",
    "    end\n",
    "\n",
    "   # Test 2: Test lightcurve with different bin sizes\n",
    "    @testset \"Different bin sizes\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_bin_sizes.fits\")\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        # Create data\n",
    "        times = Float64[1.0, 2.0, 3.0, 3.5, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 30.0, 25.0, 15.0, 10.0]\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        data = readevents(sample_file)\n",
    "    \n",
    "        # Test with bin size of 2.0\n",
    "        lc_2 =create_lightcurve(data, 2.0)\n",
    "        @test length(lc_2.timebins) == 4  # 3 bins + 1 endpoint\n",
    "        @test length(lc_2.counts) == 3\n",
    "        @test lc_2.timebins[1] == 1.0\n",
    "        @test lc_2.timebins[end] == 7.0  # Updated expected value\n",
    "        @test lc_2.counts == [2, 3, 1]  # Updated expected value\n",
    "        @test lc_2.count_error == sqrt.([2, 3, 1])  # Updated expected value\n",
    "    \n",
    "        # Test with bin size of 1.0\n",
    "        lc_1 =create_lightcurve(data, 1.0)\n",
    "        @test length(lc_1.timebins) == 6  # 5 bins + 1 endpoint\n",
    "        @test length(lc_1.counts) == 5\n",
    "        @test lc_1.timebins[1] == 1.0\n",
    "        @test lc_1.timebins[end] == 6.0\n",
    "        @test lc_1.counts == [1, 1, 2, 1, 1]  # Updated expected value\n",
    "        @test lc_1.count_error == sqrt.([1, 1, 2, 1, 1])  # Updated expected value\n",
    "    end\n",
    "    \n",
    "    # Test 3: Test lightcurve error computation methods\n",
    "    @testset \"Error computation methods\" begin\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_error_methods.fits\")\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])\n",
    "        # Create data\n",
    "        times = Float64[1.0, 2.0, 2.5, 3.0, 4.5, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 20.0, 25.0, 15.0, 10.0]\n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "        data = readevents(sample_file)\n",
    "    \n",
    "        # Test with default error method (Poisson)\n",
    "        lc =create_lightcurve(data, 1.0)\n",
    "        @test lc.count_error == sqrt.([1, 2, 1, 1, 1])  # Updated expected value\n",
    "        \n",
    "        # Add more error computation methods here if needed\n",
    "    end\n",
    "\n",
    "    # Test 4: Struct Type Validation\n",
    "    @testset \"LightCurve Struct Type Checks\" begin\n",
    "        # Create a sample FITS file for type testing\n",
    "        test_dir = mktempdir()\n",
    "        sample_file = joinpath(test_dir, \"sample_types.fits\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        f = FITS(sample_file, \"w\")\n",
    "        write(f, Int[])  # Empty primary array\n",
    "        \n",
    "        # Create test data\n",
    "        times = Float64[1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        energies = Float64[10.0, 20.0, 15.0, 25.0, 30.0]\n",
    "        \n",
    "        table = Dict{String,Array}()\n",
    "        table[\"TIME\"] = times\n",
    "        table[\"ENERGY\"] = energies\n",
    "        write(f, table)\n",
    "        close(f)\n",
    "\n",
    "        # Test type-specific instantiations\n",
    "        @testset \"Type Parametric Struct Tests\" begin\n",
    "            # Test Float64 EventList\n",
    "            data_f64 = readevents(sample_file, T = Float64)\n",
    "            @test isa(data_f64, EventList{Float64})\n",
    "            @test typeof(data_f64) == EventList{Float64}\n",
    "            \n",
    "            # Test lightcurve creation\n",
    "            lc_f64 =create_lightcurve(data_f64, 1.0)\n",
    "            @test isa(lc_f64, LightCurve{Float64})\n",
    "            @test typeof(lc_f64) == LightCurve{Float64}\n",
    "\n",
    "            # Test Float32 EventList\n",
    "            data_f32 = readevents(sample_file, T = Float32)\n",
    "            @test isa(data_f32, EventList{Float32})\n",
    "            @test typeof(data_f32) == EventList{Float32}\n",
    "\n",
    "            # Test lightcurve creation\n",
    "            lc_f32 =create_lightcurve(data_f32, 1.0)\n",
    "            @test isa(lc_f32, LightCurve{Float32})\n",
    "            @test typeof(lc_f32) == LightCurve{Float32}\n",
    "\n",
    "            # Test Int64 EventList\n",
    "            data_i64 = readevents(sample_file, T = Int64)\n",
    "            @test isa(data_i64, EventList{Int64})\n",
    "            @test typeof(data_i64) == EventList{Int64}\n",
    "\n",
    "            # Test lightcurve creation\n",
    "            lc_i64 =create_lightcurve(data_i64, 1.0)\n",
    "            @test isa(lc_i64, LightCurve{Int64})\n",
    "            @test typeof(lc_i64) == LightCurve{Int64}\n",
    "        end\n",
    "\n",
    "        # Test struct field types\n",
    "        @testset \"Struct Field Type Checks\" begin\n",
    "            data = readevents(sample_file)\n",
    "            \n",
    "            # Check filename type\n",
    "            @test isa(data.filename, String)\n",
    "            \n",
    "            # Check times and energies vector types\n",
    "            @test isa(data.times, Vector{Float64})\n",
    "            @test isa(data.energies, Vector{Float64})\n",
    "            \n",
    "            # Check metadata type\n",
    "            @test isa(data.metadata, DictMetadata)\n",
    "            @test isa(data.metadata.headers, Vector{Dict{String,Any}})\n",
    "\n",
    "            # Test lightcurve creation\n",
    "            lc =create_lightcurve(data, 1.0)\n",
    "\n",
    "            # Check timebins type\n",
    "            @test isa(lc.timebins, Vector{Float64})\n",
    "\n",
    "            # Check counts type\n",
    "            @test isa(lc.counts, Vector{Int})\n",
    "\n",
    "            # Check count_error type\n",
    "            @test isa(lc.count_error, Vector{Float64})\n",
    "\n",
    "            # Check err_method type\n",
    "            @test isa(lc.err_method, Symbol)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b41e2b2e-f628-468c-98f9-c62384028da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ResumableFunctions, StatsBase, Statistics, DataFrames\n",
    "using FFTW, NaNMath, FITSIO, Intervals\n",
    "using ProgressBars: tqdm as show_progress\n",
    "\n",
    "include(\"fourier.jl\")\n",
    "export positive_fft_bins\n",
    "export poisson_level\n",
    "export normalize_abs\n",
    "export normalize_frac\n",
    "export normalize_leahy_from_variance\n",
    "export normalize_periodograms\n",
    "export bias_term\n",
    "export raw_coherence\n",
    "export estimate_intrinsic_coherence\n",
    "export error_on_averaged_cross_spectrum\n",
    "export get_average_ctrate\n",
    "export get_flux_iterable_from_segments\n",
    "export avg_pds_from_events\n",
    "export avg_cs_from_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f766842b-e38c-42e4-917b-c2f037c61de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validate"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Abstract type representing a power spectrum, which characterizes the distribution \n",
    "of power across different frequencies in a signal.\n",
    "\n",
    "Subtypes include:\n",
    "- PowerSpectrum{T}: Represents a power spectrum for a single signal segment\n",
    "- AveragedPowerspectrum{T}: Represents a power spectrum averaged over multiple segments\n",
    "\"\"\"\n",
    "abstract type AbstractPowerSpectrum{T} end\n",
    "\n",
    "\"\"\"\n",
    "Represents a power spectrum computed from a single signal segment.\n",
    "\n",
    "## Fields\n",
    "- `freqs::Vector{T}`: Vector of frequency values \n",
    "- `power::Vector{T}`: Corresponding power values for each frequency\n",
    "- `power_errors::Vector{T}`: Uncertainty estimates for power at each frequency\n",
    "- `dt::T`: Time sampling interval\n",
    "- `n::Int`: Number of data points in the original segment\n",
    "\"\"\"\n",
    "struct PowerSpectrum{T} <: AbstractPowerSpectrum{T}\n",
    "    freqs::Vector{T}\n",
    "    power::Vector{T}\n",
    "    power_errors::Vector{T}\n",
    "    dt::T\n",
    "    n::Int\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Represents a power spectrum computed by averaging multiple signal segments.\n",
    "\n",
    "## Fields\n",
    "- `freqs::Vector{T}`: Vector of frequency values\n",
    "- `power::Vector{T}`: Average power values for each frequency\n",
    "- `power_errors::Vector{T}`: Standard error of power estimates\n",
    "- `m::Int`: Number of segments used in averaging\n",
    "- `n::Int`: Number of data points in each segment\n",
    "- `dt::T`: Time sampling interval\n",
    "\"\"\"\n",
    "struct AveragedPowerspectrum{T} <: AbstractPowerSpectrum{T}\n",
    "    freqs::Vector{T}\n",
    "    power::Vector{T} \n",
    "    power_errors::Vector{T}\n",
    "    m::Int\n",
    "    n::Int\n",
    "    dt::T\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    powerspectrum(events::EventList{T}; dt::Real=0.001,\n",
    "                 segment_size::Int=length(events.times) ÷ 32, \n",
    "                 norm::Symbol=:frac) where T -> AveragedPowerspectrum{T}\n",
    "\n",
    "Compute the power spectrum for a list of events using segmented averaging.\n",
    "\n",
    "## Arguments\n",
    "- `events::EventList{T}`: Input event list containing times and optional energies\n",
    "- `dt::Real=0.001`: Time sampling interval (default: 0.001)\n",
    "- `segment_size::Int=length(events.times) ÷ 32`: Size of each segment for FFT (default: 1/32 of total data)\n",
    "- `norm::Symbol=:frac`: Normalization method for power spectrum\n",
    "    - `:leahy`: Multiplies power by 2\n",
    "    - `:frac`: Normalizes power by mean power\n",
    "    - `:abs`: No normalization\n",
    "\n",
    "## Returns\n",
    "- `AveragedPowerspectrum{T}`: Power spectrum computed from segmented data\n",
    "\n",
    "## Throws\n",
    "- `ArgumentError` if segment size is invalid or insufficient data points\n",
    "\n",
    "## Examples\n",
    "```julia\n",
    "events = EventList(times, energies, metadata)\n",
    "ps = powerspectrum(events, dt=0.01, segment_size=1024, norm=:leahy)\n",
    "```\n",
    "\"\"\"\n",
    "function powerspectrum(events::EventList{T}; dt::Real = 0.001,\n",
    "                      segment_size::Int = length(events.times) ÷ 32, \n",
    "                      norm::Symbol = :frac) where T\n",
    "    if segment_size <= 0\n",
    "        throw(ArgumentError(\"Segment size must be positive\"))\n",
    "    end\n",
    "    if length(events.times) < segment_size\n",
    "        throw(ArgumentError(\"Not enough data points\"))\n",
    "    end\n",
    "    return _powerspectrum_averaged(events, convert(T, dt), segment_size, norm)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    _powerspectrum_averaged(events::EventList{T}, dt::T, \n",
    "                          segment_size::Int, norm::Symbol) where T -> AveragedPowerspectrum{T}\n",
    "\n",
    "Compute averaged power spectrum from event list segments.\n",
    "\n",
    "## Arguments\n",
    "- `events::EventList{T}`: Input event list\n",
    "- `dt::T`: Time sampling interval\n",
    "- `segment_size::Int`: Number of points in each segment\n",
    "- `norm::Symbol`: Normalization method for power spectrum\n",
    "\n",
    "## Returns\n",
    "- `AveragedPowerspectrum{T}`: Power spectrum averaged over multiple segments\n",
    "\n",
    "## Notes\n",
    "- Prioritizes using event energies if available, otherwise uses event times\n",
    "- Computes FFT for each segment and averages power\n",
    "- Calculates frequency-dependent power with specified normalization\n",
    "\"\"\"\n",
    "function _powerspectrum_averaged(events::EventList{T}, \n",
    "                               dt::T, \n",
    "                               segment_size::Int, \n",
    "                               norm::Symbol) where T\n",
    "    signal = events.times\n",
    "    \n",
    "    if !all(iszero, events.energies)\n",
    "        signal = events.energies\n",
    "    end\n",
    "    \n",
    "    n_segments = length(signal) ÷ segment_size\n",
    "    segments = [signal[(i-1)*segment_size+1 : i*segment_size] for i in 1:n_segments]\n",
    "    \n",
    "    # Apply Hanning window if needed\n",
    "    windowed_segments = [segment .* hanning(segment_size) for segment in segments]\n",
    "    \n",
    "    ffts = [fft(segment) for segment in windowed_segments]\n",
    "    \n",
    "    nyquist_index = segment_size ÷ 2 + 1\n",
    "    powers = [abs2.(fft[1:nyquist_index]) for fft in ffts]\n",
    "    \n",
    "    avg_power = mean(powers)\n",
    "    \n",
    "    freqs = FFTW.rfftfreq(segment_size, 1/dt)\n",
    "    \n",
    "    if length(freqs) != length(avg_power)\n",
    "        throw(ArgumentError(\"Frequency and power arrays must match\"))\n",
    "    end\n",
    "    \n",
    "    normalized_power = _normalize_power(avg_power, norm)\n",
    "    power_errors = std(powers) ./ sqrt(length(segments))\n",
    "    \n",
    "    positive_indices = 2:length(freqs)\n",
    "    \n",
    "    return AveragedPowerspectrum{T}(\n",
    "        convert(Vector{T}, freqs[positive_indices]),\n",
    "        convert(Vector{T}, normalized_power[positive_indices]),\n",
    "        convert(Vector{T}, power_errors[positive_indices]),\n",
    "        length(segments),\n",
    "        segment_size,\n",
    "        dt\n",
    "    )\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    hanning(N::Int) -> Vector{Float64}\n",
    "\n",
    "Generate a Hanning window function for signal tapering.\n",
    "\n",
    "## Arguments\n",
    "- `N::Int`: Length of the window\n",
    "\n",
    "## Returns\n",
    "- `Vector{Float64}`: Hanning window weights\n",
    "\n",
    "## Examples\n",
    "```julia\n",
    "window = hanning(1024)  # Creates a Hanning window of length 1024\n",
    "```\n",
    "\"\"\"\n",
    "function hanning(N::Int)\n",
    "    return [0.5 * (1 - cos(2π * n / (N-1))) for n in 0:N-1]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    _normalize_power(power::AbstractVector, norm::Symbol) -> Vector{Float64}\n",
    "\n",
    "Normalize power spectrum based on specified method.\n",
    "\n",
    "## Arguments\n",
    "- `power`: Input power values\n",
    "- `norm`: Normalization method (`:leahy`, `:frac`, or `:abs`)\n",
    "\n",
    "## Returns\n",
    "- `Vector{Float64}`: Normalized power values\n",
    "\n",
    "## Throws\n",
    "- `ArgumentError` for unknown normalization method\n",
    "\"\"\"\n",
    "function _normalize_power(power::AbstractVector, norm::Symbol)\n",
    "    if norm == :leahy\n",
    "        return power .* 2\n",
    "    elseif norm == :frac\n",
    "        return power ./ mean(power)\n",
    "    elseif norm == :abs\n",
    "        return power\n",
    "    else\n",
    "        throw(ArgumentError(\"Unknown normalization method: $norm\"))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Interface functions\n",
    "freqs(ps::AbstractPowerSpectrum) = ps.freqs\n",
    "power(ps::AbstractPowerSpectrum) = ps.power\n",
    "errors(ps::AbstractPowerSpectrum) = ps.power_errors\n",
    "\n",
    "# Base methods\n",
    "Base.length(ps::AbstractPowerSpectrum) = length(ps.freqs)\n",
    "Base.size(ps::AbstractPowerSpectrum) = (length(ps),)\n",
    "Base.getindex(ps::AbstractPowerSpectrum, i) = (ps.freqs[i], ps.power[i], ps.power_errors[i])\n",
    "\n",
    "# Show methods\n",
    "function Base.show(io::IO, ps::PowerSpectrum{T}) where T\n",
    "    print(io, \"PowerSpectrum{$T}(n=$(ps.n), df=$(ps.freqs[2]-ps.freqs[1]))\")\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, ps::AveragedPowerspectrum{T}) where T\n",
    "    print(io, \"AveragedPowerspectrum{$T}(n=$(ps.n), m=$(ps.m), df=$(ps.freqs[2]-ps.freqs[1]))\")\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    validate(ps::AbstractPowerSpectrum) -> Bool\n",
    "\n",
    "Validate the power spectrum structure.\n",
    "\n",
    "## Returns\n",
    "- `true` if valid, throws ArgumentError otherwise\n",
    "\n",
    "## Throws\n",
    "- `ArgumentError` if any validation checks fail\n",
    "\"\"\"\n",
    "function validate(ps::AbstractPowerSpectrum)\n",
    "    if length(ps.freqs) != length(ps.power)\n",
    "        throw(ArgumentError(\"Frequency and power arrays must have the same length\"))\n",
    "    end\n",
    "    if length(ps.power) != length(ps.power_errors)\n",
    "        throw(ArgumentError(\"Power and error arrays must have the same length\"))\n",
    "    end\n",
    "    if any(x -> x < 0, ps.power)\n",
    "        throw(ArgumentError(\"Power values must be non-negative\"))\n",
    "    end\n",
    "    if any(x -> x < 0, ps.power_errors)\n",
    "        throw(ArgumentError(\"Error values must be non-negative\"))\n",
    "    end\n",
    "    return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1be31ae-3075-4435-b3b8-fbb9a19facf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:           | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Power Spectrum Analysis | \u001b[32m  20  \u001b[39m\u001b[36m   20  \u001b[39m\u001b[0m1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"Power Spectrum Analysis\", Any[Test.DefaultTestSet(\"Basic Spectrum Creation\", Any[], 4, false, false, true, 1.743335226762e9, 1.743335227725e9, false, \"In[24]\"), Test.DefaultTestSet(\"Multiple Frequency Detection\", Any[], 2, false, false, true, 1.743335227725e9, 1.743335227809e9, false, \"In[24]\"), Test.DefaultTestSet(\"Averaged Power Spectrum\", Any[], 5, false, false, true, 1.743335227809e9, 1.743335227842e9, false, \"In[24]\"), Test.DefaultTestSet(\"Normalization Methods\", Any[], 9, false, false, true, 1.743335227842e9, 1.743335227866e9, false, \"In[24]\")], 0, false, false, true, 1.743335226762e9, 1.743335227866e9, false, \"In[24]\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@testset \"Power Spectrum Analysis\" begin\n",
    "    @testset \"Basic Spectrum Creation\" begin\n",
    "        dt = 0.001\n",
    "        T = 100.0\n",
    "        t = 0:dt:T\n",
    "        freq = 2.0\n",
    "        \n",
    "        signal = 2.0 * sin.(2π * freq * t)\n",
    "        \n",
    "        # Create empty metadata\n",
    "        metadata = DictMetadata([Dict{String,Any}()])\n",
    "        \n",
    "        events = EventList{Float64}(\n",
    "            \"test_basic.fits\",\n",
    "            collect(Float64, t),\n",
    "            Float64.(signal),\n",
    "            metadata\n",
    "        )\n",
    "    \n",
    "        ps = powerspectrum(events, dt=dt)\n",
    "        @test isa(ps, AveragedPowerspectrum)\n",
    "        @test length(ps.freqs) == length(ps.power)\n",
    "        @test length(ps.power) == length(ps.power_errors)\n",
    "        \n",
    "        freqs = ps.freqs\n",
    "        powers = ps.power\n",
    "        peak_idx = argmax(powers)\n",
    "        detected_freq = ps.freqs[peak_idx]\n",
    "        \n",
    "        @test isapprox(detected_freq, freq, rtol=0.1, atol=1/(T*dt))\n",
    "    end\n",
    "\n",
    "    @testset \"Multiple Frequency Detection\" begin\n",
    "        n_points = 2^17\n",
    "        dt = 0.001\n",
    "        t = range(0, step=dt, length=n_points)\n",
    "        T = t[end]\n",
    "        f1, f2 = 1.0, 2.5\n",
    "        \n",
    "        signal = 50.0 * (sin.(2π * f1 * t) + sin.(2π * f2 * t))\n",
    "        \n",
    "        # Create empty metadata\n",
    "        metadata = DictMetadata([Dict{String,Any}()])\n",
    "        \n",
    "        events = EventList(\n",
    "            \"test_multi.fits\",\n",
    "            collect(Float64, t),\n",
    "            Float64.(signal),\n",
    "            metadata\n",
    "        )\n",
    "\n",
    "        ps = powerspectrum(events, dt=dt)\n",
    "        \n",
    "        min_freq_idx = max(2, floor(Int, 0.1/(T*dt)))\n",
    "        freqs = ps.freqs[min_freq_idx:end]\n",
    "        powers = ps.power[min_freq_idx:end]\n",
    "        \n",
    "        peak_indices = Int[]\n",
    "        for i in 2:(length(powers)-1)\n",
    "            if powers[i] > powers[i-1] && powers[i] > powers[i+1]\n",
    "                push!(peak_indices, i)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if !isempty(peak_indices)\n",
    "            peak_freqs = freqs[peak_indices]\n",
    "            peak_powers = powers[peak_indices]\n",
    "            \n",
    "            sorted_idx = sortperm(peak_powers, rev=true)\n",
    "            peak_freqs = peak_freqs[sorted_idx]\n",
    "            \n",
    "            df = 1/T \n",
    "            found_f1 = any(f -> abs(f - f1) ≤ 8df, peak_freqs)\n",
    "            found_f2 = any(f -> abs(f - f2) ≤ 8df, peak_freqs)\n",
    "            \n",
    "            @test found_f1\n",
    "            @test found_f2\n",
    "        else\n",
    "            @test false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @testset \"Averaged Power Spectrum\" begin\n",
    "        n_points = 2^16\n",
    "        dt = 0.001\n",
    "        t = range(0, step=dt, length=n_points)\n",
    "        freq = 2.0\n",
    "        \n",
    "        signal = 20.0 * sin.(2π * freq * t)\n",
    "        \n",
    "        # Create empty metadata\n",
    "        metadata = DictMetadata([Dict{String,Any}()])\n",
    "        \n",
    "        events = EventList(\n",
    "            \"test_avg.fits\",\n",
    "            collect(Float64, t),\n",
    "            Float64.(signal),\n",
    "            metadata\n",
    "        )\n",
    "    \n",
    "        segment_size = 2048\n",
    "        \n",
    "        aps = powerspectrum(events, dt=dt, segment_size=segment_size)\n",
    "        \n",
    "        @test isa(aps, AveragedPowerspectrum)\n",
    "        @test length(aps.freqs) == length(aps.power)\n",
    "        @test length(aps.power) == length(aps.power_errors)\n",
    "        @test aps.m > 0\n",
    "        \n",
    "        powers = aps.power\n",
    "        freqs = aps.freqs\n",
    "        \n",
    "        peak_idx = argmax(powers)\n",
    "        detected_freq = freqs[peak_idx]\n",
    "        \n",
    "        df = 1/(segment_size * dt)\n",
    "        \n",
    "        @test abs(detected_freq - freq) <= 2*df\n",
    "    end\n",
    "\n",
    "    @testset \"Normalization Methods\" begin\n",
    "        n_points = 2^12\n",
    "        dt = 0.001\n",
    "        t = range(0, step=dt, length=n_points)\n",
    "        signal = sin.(2π * 2.0 * t)\n",
    "        \n",
    "        # Create empty metadata\n",
    "        metadata = DictMetadata([Dict{String,Any}()])\n",
    "        \n",
    "        events = EventList(\n",
    "            \"test_norm.fits\",\n",
    "            collect(Float64, t),\n",
    "            Float64.(signal),\n",
    "            metadata\n",
    "        )\n",
    "        \n",
    "        for norm in [:leahy, :frac, :abs]\n",
    "            ps = powerspectrum(events, dt=dt, norm=norm)\n",
    "            @test all(ps.power .>= 0)\n",
    "            @test all(ps.power_errors .>= 0)\n",
    "            @test length(ps.freqs) == length(ps.power)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e889a5-d979-48a0-aecb-7252f71805f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
